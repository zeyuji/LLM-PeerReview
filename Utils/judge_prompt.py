"""
This file contains prompt templates for model scoring across various datasets. 
It includes scoring modes (single, double, triple, quadruple) and scoring levels (3, 5, 7, 10).
"""

# TriviaQa
SINGLE_5_FACT="""
You are an expert evaluator tasked with assessing the quality of a Response generated for a Question/Instruction from the TriviaQA (factual recall) dataset in NLP.
TriviaQA (factual recall) is a dataset designed for factual recall, containing a large number of question-answer pairs based on multiple sources such as Wikipedia and books, covering a wide range of topics including history, geography, culture, entertainment, science, and more. **Its purpose is to test how well models provide the correct facts/concepts when given factual questions.**


You will be provided with a Question/Instruction and a Response generated by a model.
**Your task is to evaluate the quality of the Response by focusing on the following evaluation criteria:
Regardless of whether the entire Response contains irrelevant or nonsensical content, focus solely on whether the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question is mentioned/appears anywhere in the entire Response**:
Simply search for whether the fact/concept that can correctly answer the Question is mentioned/appears anywhere in the entire Response. If it does, the Response is considered correct.
For example, the fact "McDonnell Douglas" is correct for answering the Question "First flown on the 27th July 1972, who built the F15 Eagle fighter?". In this case, regardless of whether the entire Response contains irrelevant or nonsensical content, you should only check for the mention of the correct fact/concept in various possible expressions (e.g., "McDonnell Douglas", "mcdonell douglas", "mcdonnell douglas aerospace",  "mcdonnell douglas corp", "mc donell douglas", etc.). If any of these variations are present in the Response, it is considered correct.


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5]. Please provide **a precise integer score between [1, 2, 3, 4, 5]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
2 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **most likely does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
3 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (20%-60%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
4 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (60%-99%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
5 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response ** 100% contains** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response": x}} where x is a placeholder that you should replace with the integer score. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Strictly adhere to the scoring guidelines to provide an accurate score.**



Now here are the Question/Instruction, the Response, and your judge result:

Question/Instruction: {question}

Response: {response}

Your Python dictionary containing the score: 

"""

SINGLE_3_FACT="""
You are an expert evaluator tasked with assessing the quality of a Response generated for a Question/Instruction from the TriviaQA (factual recall) dataset in NLP.
TriviaQA (factual recall) is a dataset designed for factual recall, containing a large number of question-answer pairs based on multiple sources such as Wikipedia and books, covering a wide range of topics including history, geography, culture, entertainment, science, and more. **Its purpose is to test how well models provide the correct facts/concepts when given factual questions.**


You will be provided with a Question/Instruction and a Response generated by a model.
**Your task is to evaluate the quality of the Response by focusing on the following evaluation criteria:
Regardless of whether the entire Response contains irrelevant or nonsensical content, focus solely on whether the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question is mentioned/appears anywhere in the entire Response**:
Simply search for whether the fact/concept that can correctly answer the Question is mentioned/appears anywhere in the entire Response. If it does, the Response is considered correct.
For example, the fact "McDonnell Douglas" is correct for answering the Question "First flown on the 27th July 1972, who built the F15 Eagle fighter?". In this case, regardless of whether the entire Response contains irrelevant or nonsensical content, you should only check for the mention of the correct fact/concept in various possible expressions (e.g., "McDonnell Douglas", "mcdonell douglas", "mcdonnell douglas aerospace",  "mcdonnell douglas corp", "mc donell douglas", etc.). If any of these variations are present in the Response, it is considered correct.


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3]. Please provide **a precise integer score between [1, 2, 3]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
2 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely or very likely to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
3 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response ** 100% contains** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response": x}} where x is a placeholder that you should replace with the integer score. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Strictly adhere to the scoring guidelines to provide an accurate score.**



Now here are the Question/Instruction, the Response, and your judge result:

Question/Instruction: {question}

Response: {response}

Your Python dictionary containing the score: 

"""

SINGLE_7_FACT="""
You are an expert evaluator tasked with assessing the quality of a Response generated for a Question/Instruction from the TriviaQA (factual recall) dataset in NLP.
TriviaQA (factual recall) is a dataset designed for factual recall, containing a large number of question-answer pairs based on multiple sources such as Wikipedia and books, covering a wide range of topics including history, geography, culture, entertainment, science, and more. **Its purpose is to test how well models provide the correct facts/concepts when given factual questions.**


You will be provided with a Question/Instruction and a Response generated by a model.
**Your task is to evaluate the quality of the Response by focusing on the following evaluation criteria:
Regardless of whether the entire Response contains irrelevant or nonsensical content, focus solely on whether the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question is mentioned/appears anywhere in the entire Response**:
Simply search for whether the fact/concept that can correctly answer the Question is mentioned/appears anywhere in the entire Response. If it does, the Response is considered correct.
For example, the fact "McDonnell Douglas" is correct for answering the Question "First flown on the 27th July 1972, who built the F15 Eagle fighter?". In this case, regardless of whether the entire Response contains irrelevant or nonsensical content, you should only check for the mention of the correct fact/concept in various possible expressions (e.g., "McDonnell Douglas", "mcdonell douglas", "mcdonnell douglas aerospace",  "mcdonnell douglas corp", "mc donell douglas", etc.). If any of these variations are present in the Response, it is considered correct.


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7]. Please provide **a precise integer score between [1, 2, 3, 4, 5, 6, 7]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
2 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **most likely does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
3 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (< 40%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
4 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (40%-60%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
5 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is likely (60%-80%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
6 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (80%-99%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
7 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response ** 100% contains** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response": x}} where x is a placeholder that you should replace with the integer score. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Strictly adhere to the scoring guidelines to provide an accurate score.**



Now here are the Question/Instruction, the Response, and your judge result:

Question/Instruction: {question}

Response: {response}

Your Python dictionary containing the score: 

"""

SINGLE_10_FACT="""
You are an expert evaluator tasked with assessing the quality of a Response generated for a Question/Instruction from the TriviaQA (factual recall) dataset in NLP.
TriviaQA (factual recall) is a dataset designed for factual recall, containing a large number of question-answer pairs based on multiple sources such as Wikipedia and books, covering a wide range of topics including history, geography, culture, entertainment, science, and more. **Its purpose is to test how well models provide the correct facts/concepts when given factual questions.**


You will be provided with a Question/Instruction and a Response generated by a model.
**Your task is to evaluate the quality of the Response by focusing on the following evaluation criteria:
Regardless of whether the entire Response contains irrelevant or nonsensical content, focus solely on whether the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question is mentioned/appears anywhere in the entire Response**:
Simply search for whether the fact/concept that can correctly answer the Question is mentioned/appears anywhere in the entire Response. If it does, the Response is considered correct.
For example, the fact "McDonnell Douglas" is correct for answering the Question "First flown on the 27th July 1972, who built the F15 Eagle fighter?". In this case, regardless of whether the entire Response contains irrelevant or nonsensical content, you should only check for the mention of the correct fact/concept in various possible expressions (e.g., "McDonnell Douglas", "mcdonell douglas", "mcdonnell douglas aerospace",  "mcdonnell douglas corp", "mc donell douglas", etc.). If any of these variations are present in the Response, it is considered correct.


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]. Please provide **a precise integer score between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
2 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **most likely does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
3 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (< 40%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
4 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (40%-50%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
5 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is likely (50%-60%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
6 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is likely (60%-70%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
7 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (70%-80%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
8 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (80%-90%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
9 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (90%-99%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
10 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response ** 100% contains** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response": x}} where x is a placeholder that you should replace with the integer score. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Strictly adhere to the scoring guidelines to provide an accurate score.**



Now here are the Question/Instruction, the Response, and your judge result:

Question/Instruction: {question}

Response: {response}

Your Python dictionary containing the score: 

"""

DOUBLE_5_FACT="""
You are an expert evaluator tasked with assessing qualities of the two Responses generated for a Question/Instruction from the TriviaQA (factual recall) dataset in NLP.
TriviaQA (factual recall) is a dataset designed for factual recall, containing a large number of question-answer pairs based on multiple sources such as Wikipedia and books, covering a wide range of topics including history, geography, culture, entertainment, science, and more. **Its purpose is to test how well models provide the correct facts/concepts when given factual questions.**


You will be provided with a Question/Instruction and two Responses generated from different models.
**Your task is to evaluate the qualities of the two Responses by focusing on the following evaluation criteria:
For each Response, regardless of whether the entire Response contains irrelevant or nonsensical content, focus solely on whether the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question is mentioned/appears anywhere in the entire Response**:
Simply search for whether the fact/concept that can correctly answer the Question is mentioned/appears anywhere in the entire Response. If it does, the Response is considered correct.
For example, the fact "McDonnell Douglas" is correct for answering the Question "First flown on the 27th July 1972, who built the F15 Eagle fighter?". In this case, regardless of whether the entire Response contains irrelevant or nonsensical content, you should only check for the mention of the correct fact/concept in various possible expressions (e.g., "McDonnell Douglas", "mcdonell douglas", "mcdonnell douglas aerospace",  "mcdonnell douglas corp", "mc donell douglas", etc.). If any of these variations are present in the Response, it is considered correct.



In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5]. Please provide **two precise integer scores between [1, 2, 3, 4, 5]** by **strictly and meticulously adhering to the following scoring guidelines**:  
1 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
2 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **most likely does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
3 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (20%-60%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
4 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (60%-99%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
5 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response ** 100% contains** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, "Score for the Response Two": y}} where x,y are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the two Responses,and strictly adhere to the scoring guidelines to provide two accurate scores.**


Now here are the Question/Instruction, the Responses, and your judge result:

Question/Instruction: {question}

Response One: {response1}

Response Two: {response2}

Your Python dictionary containing the two scores:

"""

DOUBLE_3_FACT="""
You are an expert evaluator tasked with assessing qualities of the two Responses generated for a Question/Instruction from the TriviaQA (factual recall) dataset in NLP.
TriviaQA (factual recall) is a dataset designed for factual recall, containing a large number of question-answer pairs based on multiple sources such as Wikipedia and books, covering a wide range of topics including history, geography, culture, entertainment, science, and more. **Its purpose is to test how well models provide the correct facts/concepts when given factual questions.**


You will be provided with a Question/Instruction and two Responses generated from different models.
**Your task is to evaluate the qualities of the two Responses by focusing on the following evaluation criteria:
For each Response, regardless of whether the entire Response contains irrelevant or nonsensical content, focus solely on whether the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question is mentioned/appears anywhere in the entire Response**:
Simply search for whether the fact/concept that can correctly answer the Question is mentioned/appears anywhere in the entire Response. If it does, the Response is considered correct.
For example, the fact "McDonnell Douglas" is correct for answering the Question "First flown on the 27th July 1972, who built the F15 Eagle fighter?". In this case, regardless of whether the entire Response contains irrelevant or nonsensical content, you should only check for the mention of the correct fact/concept in various possible expressions (e.g., "McDonnell Douglas", "mcdonell douglas", "mcdonnell douglas aerospace",  "mcdonnell douglas corp", "mc donell douglas", etc.). If any of these variations are present in the Response, it is considered correct.


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3]. Please provide **two precise integer scores between [1, 2, 3]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
2 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely or very likely to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
3 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response ** 100% contains** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, "Score for the Response Two": y}} where x,y are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the two Responses,and strictly adhere to the scoring guidelines to provide two accurate scores.**


Now here are the Question/Instruction, the Responses, and your judge result:

Question/Instruction: {question}

Response One: {response1}

Response Two: {response2}

Your Python dictionary containing the two scores:

"""

DOUBLE_7_FACT="""
You are an expert evaluator tasked with assessing qualities of the two Responses generated for a Question/Instruction from the TriviaQA (factual recall) dataset in NLP.
TriviaQA (factual recall) is a dataset designed for factual recall, containing a large number of question-answer pairs based on multiple sources such as Wikipedia and books, covering a wide range of topics including history, geography, culture, entertainment, science, and more. **Its purpose is to test how well models provide the correct facts/concepts when given factual questions.**


You will be provided with a Question/Instruction and two Responses generated from different models.
**Your task is to evaluate the qualities of the two Responses by focusing on the following evaluation criteria:
For each Response, regardless of whether the entire Response contains irrelevant or nonsensical content, focus solely on whether the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question is mentioned/appears anywhere in the entire Response**:
Simply search for whether the fact/concept that can correctly answer the Question is mentioned/appears anywhere in the entire Response. If it does, the Response is considered correct.
For example, the fact "McDonnell Douglas" is correct for answering the Question "First flown on the 27th July 1972, who built the F15 Eagle fighter?". In this case, regardless of whether the entire Response contains irrelevant or nonsensical content, you should only check for the mention of the correct fact/concept in various possible expressions (e.g., "McDonnell Douglas", "mcdonell douglas", "mcdonnell douglas aerospace",  "mcdonnell douglas corp", "mc donell douglas", etc.). If any of these variations are present in the Response, it is considered correct.


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7]. Please provide **two precise integer scores between [1, 2, 3, 4, 5, 6, 7]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
2 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **most likely does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
3 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (< 40%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
4 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (40%-60%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
5 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is likely (60%-80%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
6 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (80%-99%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
7 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response ** 100% contains** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, "Score for the Response Two": y}} where x,y are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the two Responses,and strictly adhere to the scoring guidelines to provide two accurate scores.**


Now here are the Question/Instruction, the Responses, and your judge result:

Question/Instruction: {question}

Response One: {response1}

Response Two: {response2}

Your Python dictionary containing the two scores:

"""

DOUBLE_10_FACT="""
You are an expert evaluator tasked with assessing qualities of the two Responses generated for a Question/Instruction from the TriviaQA (factual recall) dataset in NLP.
TriviaQA (factual recall) is a dataset designed for factual recall, containing a large number of question-answer pairs based on multiple sources such as Wikipedia and books, covering a wide range of topics including history, geography, culture, entertainment, science, and more. **Its purpose is to test how well models provide the correct facts/concepts when given factual questions.**


You will be provided with a Question/Instruction and two Responses generated from different models.
**Your task is to evaluate the qualities of the two Responses by focusing on the following evaluation criteria:
For each Response, regardless of whether the entire Response contains irrelevant or nonsensical content, focus solely on whether the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question is mentioned/appears anywhere in the entire Response**:
Simply search for whether the fact/concept that can correctly answer the Question is mentioned/appears anywhere in the entire Response. If it does, the Response is considered correct.
For example, the fact "McDonnell Douglas" is correct for answering the Question "First flown on the 27th July 1972, who built the F15 Eagle fighter?". In this case, regardless of whether the entire Response contains irrelevant or nonsensical content, you should only check for the mention of the correct fact/concept in various possible expressions (e.g., "McDonnell Douglas", "mcdonell douglas", "mcdonnell douglas aerospace",  "mcdonnell douglas corp", "mc donell douglas", etc.). If any of these variations are present in the Response, it is considered correct.


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]. Please provide **two precise integer scores between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
2 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **most likely does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
3 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (< 40%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
4 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (40%-50%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
5 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is likely (50%-60%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
6 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is likely (60%-70%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
7 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (70%-80%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
8 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (80%-90%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
9 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (90%-99%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
10 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response ** 100% contains** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, "Score for the Response Two": y}} where x,y are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the two Responses,and strictly adhere to the scoring guidelines to provide two accurate scores.**


Now here are the Question/Instruction, the Responses, and your judge result:

Question/Instruction: {question}

Response One: {response1}

Response Two: {response2}

Your Python dictionary containing the two scores:

"""

TRIPLE_5_FACT="""
You are an expert evaluator tasked with assessing qualities of the three Responses generated for a Question/Instruction from the TriviaQA (factual recall) dataset in NLP.
TriviaQA (factual recall) is a dataset designed for factual recall, containing a large number of question-answer pairs based on multiple sources such as Wikipedia and books, covering a wide range of topics including history, geography, culture, entertainment, science, and more. **Its purpose is to test how well models provide the correct facts/concepts when given factual questions.**


You will be provided with a Question/Instruction and three Responses generated from different models.
**Your task is to evaluate the qualities of the three Responses by focusing on the following evaluation criteria:
For each Response, regardless of whether the entire Response contains irrelevant or nonsensical content, focus solely on whether the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question is mentioned/appears anywhere in the entire Response**:
Simply search for whether the fact/concept that can correctly answer the Question is mentioned/appears anywhere in the entire Response. If it does, the Response is considered correct.
For example, the fact "McDonnell Douglas" is correct for answering the Question "First flown on the 27th July 1972, who built the F15 Eagle fighter?". In this case, regardless of whether the entire Response contains irrelevant or nonsensical content, you should only check for the mention of the correct fact/concept in various possible expressions (e.g., "McDonnell Douglas", "mcdonell douglas", "mcdonnell douglas aerospace",  "mcdonnell douglas corp", "mc donell douglas", etc.). If any of these variations are present in the Response, it is considered correct.



In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5]. Please provide **three precise integer scores between [1, 2, 3, 4, 5]** by **strictly and meticulously adhering to the following scoring guidelines**:  
1 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
2 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **most likely does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
3 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (20%-60%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
4 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (60%-99%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
5 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response ** 100% contains** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z}} where x,y,z are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the three Responses,and strictly adhere to the scoring guidelines to provide three accurate scores.**


Now here are the Question/Instruction, the Responses, and your judge result:

Question/Instruction: {question}

Response One: {response1}

Response Two: {response2}

Response Three: {response3}

Your Python dictionary containing the three scores:

"""

TRIPLE_3_FACT="""
You are an expert evaluator tasked with assessing qualities of the three Responses generated for a Question/Instruction from the TriviaQA (factual recall) dataset in NLP.
TriviaQA (factual recall) is a dataset designed for factual recall, containing a large number of question-answer pairs based on multiple sources such as Wikipedia and books, covering a wide range of topics including history, geography, culture, entertainment, science, and more. **Its purpose is to test how well models provide the correct facts/concepts when given factual questions.**


You will be provided with a Question/Instruction and three Responses generated from different models.
**Your task is to evaluate the qualities of the three Responses by focusing on the following evaluation criteria:
For each Response, regardless of whether the entire Response contains irrelevant or nonsensical content, focus solely on whether the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question is mentioned/appears anywhere in the entire Response**:
Simply search for whether the fact/concept that can correctly answer the Question is mentioned/appears anywhere in the entire Response. If it does, the Response is considered correct.
For example, the fact "McDonnell Douglas" is correct for answering the Question "First flown on the 27th July 1972, who built the F15 Eagle fighter?". In this case, regardless of whether the entire Response contains irrelevant or nonsensical content, you should only check for the mention of the correct fact/concept in various possible expressions (e.g., "McDonnell Douglas", "mcdonell douglas", "mcdonnell douglas aerospace",  "mcdonnell douglas corp", "mc donell douglas", etc.). If any of these variations are present in the Response, it is considered correct.


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3]. Please provide **three precise integer scores between [1, 2, 3]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
2 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely or very likely to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
3 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response ** 100% contains** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z}} where x,y,z are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the three Responses,and strictly adhere to the scoring guidelines to provide three accurate scores.**


Now here are the Question/Instruction, the Responses, and your judge result:

Question/Instruction: {question}

Response One: {response1}

Response Two: {response2}

Response Three: {response3}

Your Python dictionary containing the three scores:

"""

TRIPLE_7_FACT="""
You are an expert evaluator tasked with assessing qualities of the three Responses generated for a Question/Instruction from the TriviaQA (factual recall) dataset in NLP.
TriviaQA (factual recall) is a dataset designed for factual recall, containing a large number of question-answer pairs based on multiple sources such as Wikipedia and books, covering a wide range of topics including history, geography, culture, entertainment, science, and more. **Its purpose is to test how well models provide the correct facts/concepts when given factual questions.**


You will be provided with a Question/Instruction and three Responses generated from different models.
**Your task is to evaluate the qualities of the three Responses by focusing on the following evaluation criteria:
For each Response, regardless of whether the entire Response contains irrelevant or nonsensical content, focus solely on whether the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question is mentioned/appears anywhere in the entire Response**:
Simply search for whether the fact/concept that can correctly answer the Question is mentioned/appears anywhere in the entire Response. If it does, the Response is considered correct.
For example, the fact "McDonnell Douglas" is correct for answering the Question "First flown on the 27th July 1972, who built the F15 Eagle fighter?". In this case, regardless of whether the entire Response contains irrelevant or nonsensical content, you should only check for the mention of the correct fact/concept in various possible expressions (e.g., "McDonnell Douglas", "mcdonell douglas", "mcdonnell douglas aerospace",  "mcdonnell douglas corp", "mc donell douglas", etc.). If any of these variations are present in the Response, it is considered correct.


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7]. Please provide **three precise integer scores between [1, 2, 3, 4, 5, 6, 7]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
2 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **most likely does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
3 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (< 40%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
4 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (40%-60%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
5 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is likely (60%-80%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
6 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (80%-99%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
7 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response ** 100% contains** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z}} where x,y,z are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the three Responses,and strictly adhere to the scoring guidelines to provide three accurate scores.**


Now here are the Question/Instruction, the Responses, and your judge result:

Question/Instruction: {question}

Response One: {response1}

Response Two: {response2}

Response Three: {response3}

Your Python dictionary containing the three scores:

"""

TRIPLE_10_FACT="""
You are an expert evaluator tasked with assessing qualities of the three Responses generated for a Question/Instruction from the TriviaQA (factual recall) dataset in NLP.
TriviaQA (factual recall) is a dataset designed for factual recall, containing a large number of question-answer pairs based on multiple sources such as Wikipedia and books, covering a wide range of topics including history, geography, culture, entertainment, science, and more. **Its purpose is to test how well models provide the correct facts/concepts when given factual questions.**


You will be provided with a Question/Instruction and three Responses generated from different models.
**Your task is to evaluate the qualities of the three Responses by focusing on the following evaluation criteria:
For each Response, regardless of whether the entire Response contains irrelevant or nonsensical content, focus solely on whether the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question is mentioned/appears anywhere in the entire Response**:
Simply search for whether the fact/concept that can correctly answer the Question is mentioned/appears anywhere in the entire Response. If it does, the Response is considered correct.
For example, the fact "McDonnell Douglas" is correct for answering the Question "First flown on the 27th July 1972, who built the F15 Eagle fighter?". In this case, regardless of whether the entire Response contains irrelevant or nonsensical content, you should only check for the mention of the correct fact/concept in various possible expressions (e.g., "McDonnell Douglas", "mcdonell douglas", "mcdonnell douglas aerospace",  "mcdonnell douglas corp", "mc donell douglas", etc.). If any of these variations are present in the Response, it is considered correct.


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]. Please provide **three precise integer scores between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
2 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **most likely does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
3 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (< 40%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
4 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (40%-50%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
5 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is likely (50%-60%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
6 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is likely (60%-70%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
7 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (70%-80%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
8 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (80%-90%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
9 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (90%-99%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
10 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response ** 100% contains** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.



Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z}} where x,y,z are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the three Responses,and strictly adhere to the scoring guidelines to provide three accurate scores.**


Now here are the Question/Instruction, the Responses, and your judge result:

Question/Instruction: {question}

Response One: {response1}

Response Two: {response2}

Response Three: {response3}

Your Python dictionary containing the three scores:

"""

MULTI_5_FACT="""
You are an expert evaluator tasked with assessing qualities of the four Responses generated for a Question/Instruction from the TriviaQA (factual recall) dataset in NLP.
TriviaQA (factual recall) is a dataset designed for factual recall, containing a large number of question-answer pairs based on multiple sources such as Wikipedia and books, covering a wide range of topics including history, geography, culture, entertainment, science, and more. **Its purpose is to test how well models provide the correct facts/concepts when given factual questions.**


You will be provided with a Question/Instruction and four Responses generated from different models.
**Your task is to evaluate the qualities of the four Responses by focusing on the following evaluation criteria:
For each Response, regardless of whether the entire Response contains irrelevant or nonsensical content, focus solely on whether the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question is mentioned/appears anywhere in the entire Response**:
Simply search for whether the fact/concept that can correctly answer the Question is mentioned/appears anywhere in the entire Response. If it does, the Response is considered correct.
For example, the fact "McDonnell Douglas" is correct for answering the Question "First flown on the 27th July 1972, who built the F15 Eagle fighter?". In this case, regardless of whether the entire Response contains irrelevant or nonsensical content, you should only check for the mention of the correct fact/concept in various possible expressions (e.g., "McDonnell Douglas", "mcdonell douglas", "mcdonnell douglas aerospace",  "mcdonnell douglas corp", "mc donell douglas", etc.). If any of these variations are present in the Response, it is considered correct.



In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5]. Please provide **four precise integer scores between [1, 2, 3, 4, 5]** by **strictly and meticulously adhering to the following scoring guidelines**:  
1 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
2 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **most likely does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
3 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (20%-60%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
4 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (60%-99%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
5 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response ** 100% contains** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z, "Score for the Response Four": w}} where x,y,z,w are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the four Responses,and strictly adhere to the scoring guidelines to provide three accurate scores.**


Now here are the Question/Instruction, the Responses, and your judge result:

Question/Instruction: {question}

Response One: {response1}

Response Two: {response2}

Response Three: {response3}

Response Four: {response4}

Your Python dictionary containing the four scores:

"""

MULTI_3_FACT="""
You are an expert evaluator tasked with assessing qualities of the four Responses generated for a Question/Instruction from the TriviaQA (factual recall) dataset in NLP.
TriviaQA (factual recall) is a dataset designed for factual recall, containing a large number of question-answer pairs based on multiple sources such as Wikipedia and books, covering a wide range of topics including history, geography, culture, entertainment, science, and more. **Its purpose is to test how well models provide the correct facts/concepts when given factual questions.**


You will be provided with a Question/Instruction and four Responses generated from different models.
**Your task is to evaluate the qualities of the four Responses by focusing on the following evaluation criteria:
For each Response, regardless of whether the entire Response contains irrelevant or nonsensical content, focus solely on whether the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question is mentioned/appears anywhere in the entire Response**:
Simply search for whether the fact/concept that can correctly answer the Question is mentioned/appears anywhere in the entire Response. If it does, the Response is considered correct.
For example, the fact "McDonnell Douglas" is correct for answering the Question "First flown on the 27th July 1972, who built the F15 Eagle fighter?". In this case, regardless of whether the entire Response contains irrelevant or nonsensical content, you should only check for the mention of the correct fact/concept in various possible expressions (e.g., "McDonnell Douglas", "mcdonell douglas", "mcdonnell douglas aerospace",  "mcdonnell douglas corp", "mc donell douglas", etc.). If any of these variations are present in the Response, it is considered correct.



In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3]. Please provide **four precise integer scores between [1, 2, 3]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
2 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely or very likely to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
3 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response ** 100% contains** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z, "Score for the Response Four": w}} where x,y,z,w are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the four Responses,and strictly adhere to the scoring guidelines to provide three accurate scores.**


Now here are the Question/Instruction, the Responses, and your judge result:

Question/Instruction: {question}

Response One: {response1}

Response Two: {response2}

Response Three: {response3}

Response Four: {response4}

Your Python dictionary containing the four scores:
"""

MULTI_7_FACT="""
You are an expert evaluator tasked with assessing qualities of the four Responses generated for a Question/Instruction from the TriviaQA (factual recall) dataset in NLP.
TriviaQA (factual recall) is a dataset designed for factual recall, containing a large number of question-answer pairs based on multiple sources such as Wikipedia and books, covering a wide range of topics including history, geography, culture, entertainment, science, and more. **Its purpose is to test how well models provide the correct facts/concepts when given factual questions.**


You will be provided with a Question/Instruction and four Responses generated from different models.
**Your task is to evaluate the qualities of the four Responses by focusing on the following evaluation criteria:
For each Response, regardless of whether the entire Response contains irrelevant or nonsensical content, focus solely on whether the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question is mentioned/appears anywhere in the entire Response**:
Simply search for whether the fact/concept that can correctly answer the Question is mentioned/appears anywhere in the entire Response. If it does, the Response is considered correct.
For example, the fact "McDonnell Douglas" is correct for answering the Question "First flown on the 27th July 1972, who built the F15 Eagle fighter?". In this case, regardless of whether the entire Response contains irrelevant or nonsensical content, you should only check for the mention of the correct fact/concept in various possible expressions (e.g., "McDonnell Douglas", "mcdonell douglas", "mcdonnell douglas aerospace",  "mcdonnell douglas corp", "mc donell douglas", etc.). If any of these variations are present in the Response, it is considered correct.



In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7]. Please provide **four precise integer scores between [1, 2, 3, 4, 5, 6, 7]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
2 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **most likely does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
3 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (< 40%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
4 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (40%-60%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
5 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is likely (60%-80%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
6 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (80%-99%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
7 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response ** 100% contains** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z, "Score for the Response Four": w}} where x,y,z,w are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the four Responses,and strictly adhere to the scoring guidelines to provide three accurate scores.**


Now here are the Question/Instruction, the Responses, and your judge result:

Question/Instruction: {question}

Response One: {response1}

Response Two: {response2}

Response Three: {response3}

Response Four: {response4}

Your Python dictionary containing the four scores:
"""

MULTI_10_FACT="""
You are an expert evaluator tasked with assessing qualities of the four Responses generated for a Question/Instruction from the TriviaQA (factual recall) dataset in NLP.
TriviaQA (factual recall) is a dataset designed for factual recall, containing a large number of question-answer pairs based on multiple sources such as Wikipedia and books, covering a wide range of topics including history, geography, culture, entertainment, science, and more. **Its purpose is to test how well models provide the correct facts/concepts when given factual questions.**


You will be provided with a Question/Instruction and four Responses generated from different models.
**Your task is to evaluate the qualities of the four Responses by focusing on the following evaluation criteria:
For each Response, regardless of whether the entire Response contains irrelevant or nonsensical content, focus solely on whether the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question is mentioned/appears anywhere in the entire Response**:
Simply search for whether the fact/concept that can correctly answer the Question is mentioned/appears anywhere in the entire Response. If it does, the Response is considered correct.
For example, the fact "McDonnell Douglas" is correct for answering the Question "First flown on the 27th July 1972, who built the F15 Eagle fighter?". In this case, regardless of whether the entire Response contains irrelevant or nonsensical content, you should only check for the mention of the correct fact/concept in various possible expressions (e.g., "McDonnell Douglas", "mcdonell douglas", "mcdonnell douglas aerospace",  "mcdonnell douglas corp", "mc donell douglas", etc.). If any of these variations are present in the Response, it is considered correct.


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]. Please provide **four precise integer scores between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
2 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **most likely does not contain** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues)  that can correctly answer the Question.
3 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (< 40%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
4 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **seems likely (40%-50%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
5 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is likely (50%-60%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
6 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is likely (60%-70%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
7 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (70%-80%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
8 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (80%-90%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
9 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response **is highly likely (90%-99%) to contain**  the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.
10 = Regardless of whether the entire Response contains irrelevant or nonsensical content, the Response ** 100% contains** the fact/concept (including different expressions referring to the same fact/concept, such as variations in capitalization, aliases, or minor formatting issues) that can correctly answer the Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z, "Score for the Response Four": w}} where x,y,z,w are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the four Responses,and strictly adhere to the scoring guidelines to provide three accurate scores.**


Now here are the Question/Instruction, the Responses, and your judge result:

Question/Instruction: {question}

Response One: {response1}

Response Two: {response2}

Response Three: {response3}

Response Four: {response4}

Your Python dictionary containing the four scores:
"""


# GSM8k / MATH
SINGLE_5_MATH="""
You are an expert evaluator tasked with assessing the quality of Response to math problems from the GSM8k/MATH dataset in NLP.
You will be provided with an Instruction/Question and a Response generated by a model.


Your task is to evaluate the quality of the Response by focusing on the following evaluation criteria:
After carefully analyzing the math problem and deriving a final answer yourself, regardless of whether the mathematical reasoning or analysis in the Response is correct or reasonable, or whether the Response contains irrelevant, redundant or repetitive content, your evaluation should focus solely on two possible scenarios (**for each Response, only one of the following two cases applies**):
**(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply search for whether the correct answer to the math Question is mentioned/appears in any of 
these sentences.**
**(Case B) If the Response does not contain any sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply check whether **the LAST single numerical number in the entire Response** is the correct answer (usually a single numerical value) to the math Question.**

In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5]. Please provide **a precise integer score between [1, 2, 3, 4, 5]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is not** the correct answer (usually a single numerical value) to the math Question.
2 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **most likely do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response *is most likely not** the correct answer (usually a single numerical value) to the math Question.
3 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (20%-60%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely to be (20%-60%)** the correct answer (usually a single numerical value) to the math Question.
4 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (60%-99%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely to be (60%-99%)** the correct answer (usually a single numerical value) to the math Question.
5 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **definitely contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is definitely** the correct answer (usually a single numerical value) to the math Question.

Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response": x}} where x is a placeholder that you should replace with the integer score. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Strictly adhere to the scoring guidelines to provide an accurate score.**


Now here are the Instruction/Question, the Response, and your judge result:

Instruction/Question: {question}

Response: {response}

Your Python dictionary containing the score: 


"""

SINGLE_3_MATH="""
You are an expert evaluator tasked with assessing the quality of Response to math problems from the GSM8k/MATH dataset in NLP.
You will be provided with an Instruction/Question and a Response generated by a model.


Your task is to evaluate the quality of the Response by focusing on the following evaluation criteria:
After carefully analyzing the math problem and deriving a final answer yourself, regardless of whether the mathematical reasoning or analysis in the Response is correct or reasonable, or whether the Response contains irrelevant, redundant or repetitive content, your evaluation should focus solely on two possible scenarios (**for each Response, only one of the following two cases applies**):
**(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply search for whether the correct answer to the math Question is mentioned/appears in any of 
these sentences.**
**(Case B) If the Response does not contain any sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply check whether **the LAST single numerical number in the entire Response** is the correct answer (usually a single numerical value) to the math Question.**


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3]. Please provide **a precise integer score between [1, 2, 3]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer  sentences **do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is not** the correct answer (usually a single numerical value) to the math Question.
2 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer  sentences **seems likely or very likely to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely or very likely to be** the correct answer (usually a single numerical value) to the math Question.
3 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer  sentences **100% contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **100% is** the correct answer (usually a single numerical value) to the math Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response": x}} where x is a placeholder that you should replace with the integer score. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Strictly adhere to the scoring guidelines to provide an accurate score.**


Now here are the Instruction/Question, the Response, and your judge result:

Instruction/Question: {question}

Response: {response}

Your Python dictionary containing the score: 

"""

SINGLE_7_MATH="""
You are an expert evaluator tasked with assessing the quality of Response to math problems from the GSM8k/MATH dataset in NLP.
You will be provided with an Instruction/Question and a Response generated by a model.


Your task is to evaluate the quality of the Response by focusing on the following evaluation criteria:
After carefully analyzing the math problem and deriving a final answer yourself, regardless of whether the mathematical reasoning or analysis in the Response is correct or reasonable, or whether the Response contains irrelevant, redundant or repetitive content, your evaluation should focus solely on two possible scenarios (**for each Response, only one of the following two cases applies**):
**(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply search for whether the correct answer to the math Question is mentioned/appears in any of 
these sentences.**
**(Case B) If the Response does not contain any sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply check whether **the LAST single numerical number in the entire Response** is the correct answer (usually a single numerical value) to the math Question.**



In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7]. Please provide **a precise integer score between  [1, 2, 3, 4, 5, 6, 7]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is not** the correct answer (usually a single numerical value) to the math Question.
2 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **most likely do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response *is most likely not** the correct answer (usually a single numerical value) to the math Question.
3 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (< 40%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely (< 40%) to be ** the correct answer (usually a single numerical value) to the math Question.
4 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (40%-60%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely (40%-60%) to be** the 
5 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are likely (60%-80%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is likely to be (60%-80%)** the correct answer (usually a single numerical value) to the math Question.
6 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (80%-99%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely (80%-99%) to be** the correct answer (usually a single numerical value) to the math Question.
7 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **definitely contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is definitely** the correct answer (usually a single numerical value) to the math Question.



Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response": x}} where x is a placeholder that you should replace with the integer score. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Strictly adhere to the scoring guidelines to provide an accurate score.**


Now here are the Instruction/Question, the Response, and your judge result:

Instruction/Question: {question}

Response: {response}

Your Python dictionary containing the score: 

"""

SINGLE_10_MATH="""
You are an expert evaluator tasked with assessing the quality of Response to math problems from the GSM8k/MATH dataset in NLP.
You will be provided with an Instruction/Question and a Response generated by a model.


Your task is to evaluate the quality of the Response by focusing on the following evaluation criteria:
After carefully analyzing the math problem and deriving a final answer yourself, regardless of whether the mathematical reasoning or analysis in the Response is correct or reasonable, or whether the Response contains irrelevant, redundant or repetitive content, your evaluation should focus solely on two possible scenarios (**for each Response, only one of the following two cases applies**):
**(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply search for whether the correct answer to the math Question is mentioned/appears in any of 
these sentences.**
**(Case B) If the Response does not contain any sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply check whether **the LAST single numerical number in the entire Response** is the correct answer (usually a single numerical value) to the math Question.**



In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]. Please provide **a precise integer score between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is not** the correct answer (usually a single numerical value) to the math Question.
2 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **most likely do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response *is most likely not** the correct answer (usually a single numerical value) to the math Question.
3 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (< 40%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely (< 40%) to be** the 
correct answer (usually a single numerical value) to the math Question.
4 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (40%-50%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely (40%-50%) to be** the 
correct answer (usually a single numerical value) to the math Question.
5 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are likely (50%-60%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is likely to be (50%-60%)** the correct answer (usually a single numerical value) to the math Question.
6 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are likely (60%-70%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is likely to be (60%-70%)** the correct answer (usually a single numerical value) to the math Question.
7 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (70%-80%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely (70%-80%) to be** the correct answer (usually a single numerical value) to the math Question.
8 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (80%-90%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely (80%-90%) to be** the correct answer (usually a single numerical value) to the math Question.
9 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (90%-99%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely (90%-99%) to be** the correct answer (usually a single numerical value) to the math Question.
10 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **definitely contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is definitely** the correct answer (usually a single numerical value) to the math Question.



Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response": x}} where x is a placeholder that you should replace with the integer score. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Strictly adhere to the scoring guidelines to provide an accurate score.**


Now here are the Instruction/Question, the Response, and your judge result:

Instruction/Question: {question}

Response: {response}

Your Python dictionary containing the score: 

"""

DOUBLE_5_MATH="""
You are an expert evaluator tasked with assessing the qualities of two Responses to math problems from the GSM8k/MATH dataset in NLP.
You will be provided with an Instruction/Question and two responses generated by different models.


Your task is to evaluate the qualities of two Responses  by focusing on the following evaluation criteria:
After carefully analyzing the math problem and deriving a final answer yourself, for each Response, regardless of whether the mathematical reasoning or analysis in the Response is correct or reasonable, or whether the Response contains irrelevant, redundant or repetitive content, your evaluation should focus solely on two possible scenarios (**for each Response, only one of the following two cases applies**):
**(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply search for whether the correct answer to the math Question is mentioned/appears in any of 
these sentences.**
**(Case B) If the Response does not contain any sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply check whether **the LAST single numerical number in the entire Response** is the correct answer (usually a single numerical value) to the math Question.**

In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5]. Please provide **two precise integer scores between [1, 2, 3, 4, 5]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is not** the correct answer (usually a single numerical value) to the math Question.
2 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **most likely do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response *is most likely not** the correct answer (usually a single numerical value) to the math Question.
3 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (20%-60%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely to be (20%-60%)** the correct answer (usually a single numerical value) to the math Question.
4 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (60%-99%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely to be (60%-99%)** the correct answer (usually a single numerical value) to the math Question.
5 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **definitely contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is definitely** the correct answer (usually a single numerical value) to the math Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, Score for the Response Two": y}} where x,y are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the two Responses,and strictly adhere to the scoring guidelines to provide two accurate scores.**

Now here are the Instruction/Question, the Responses, and your judge result:

Instruction/Question: {question}

Response One: {response1}

Response Two: {response2}

Your Python dictionary containing the two scores:

"""

DOUBLE_3_MATH="""
You are an expert evaluator tasked with assessing the qualities of two Responses to math problems from the GSM8k/MATH dataset in NLP.
You will be provided with an Instruction/Question and two responses generated by different models.


Your task is to evaluate the qualities of two Responses by focusing on the following evaluation criteria:
After carefully analyzing the math problem and deriving a final answer yourself, for each Response, regardless of whether the mathematical reasoning or analysis in the Response is correct or reasonable, or whether the Response contains irrelevant, redundant or repetitive content, your evaluation should focus solely on two possible scenarios (**for each Response, only one of the following two cases applies**):
**(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply search for whether the correct answer to the math Question is mentioned/appears in any of 
these sentences.**
**(Case B) If the Response does not contain any sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply check whether **the LAST single numerical number in the entire Response** is the correct answer (usually a single numerical value) to the math Question.**

In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3]. Please provide **two precise integer scores between [1, 2, 3]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer  sentences **do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is not** the correct answer (usually a single numerical value) to the math Question.
2 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer  sentences **seems likely or very likely to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely or very likely to be** the correct answer (usually a single numerical value) to the math Question.
3 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer  sentences **100% contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **100% is** the correct answer (usually a single numerical value) to the math Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, Score for the Response Two": y}} where x,y are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the two Responses,and strictly adhere to the scoring guidelines to provide two accurate scores.**

Now here are the Instruction/Question, the Responses, and your judge result:

Instruction/Question: {question}

Response One: {response1}

Response Two: {response2}

Your Python dictionary containing the two scores:

"""

DOUBLE_7_MATH="""
You are an expert evaluator tasked with assessing the qualities of two Responses to math problems from the GSM8k/MATH dataset in NLP.
You will be provided with an Instruction/Question and two responses generated by different models.


Your task is to evaluate the qualities of two Responses by focusing on the following evaluation criteria:
After carefully analyzing the math problem and deriving a final answer yourself, for each Response, regardless of whether the mathematical reasoning or analysis in the Response is correct or reasonable, or whether the Response contains irrelevant, redundant or repetitive content, your evaluation should focus solely on two possible scenarios (**for each Response, only one of the following two cases applies**):
**(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply search for whether the correct answer to the math Question is mentioned/appears in any of 
these sentences.**
**(Case B) If the Response does not contain any sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply check whether **the LAST single numerical number in the entire Response** is the correct answer (usually a single numerical value) to the math Question.**


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7]. Please provide **two precise integer scores between  [1, 2, 3, 4, 5, 6, 7]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is not** the correct answer (usually a single numerical value) to the math Question.
2 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **most likely do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response *is most likely not** the correct answer (usually a single numerical value) to the math Question.
3 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (< 40%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely (< 40%) to be ** the correct answer (usually a single numerical value) to the math Question.
4 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (40%-60%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely (40%-60%) to be** the 
5 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are likely (60%-80%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is likely to be (60%-80%)** the correct answer (usually a single numerical value) to the math Question.
6 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (80%-99%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely (80%-99%) to be** the correct answer (usually a single numerical value) to the math Question.
7 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **definitely contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is definitely** the correct answer (usually a single numerical value) to the math Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, Score for the Response Two": y}} where x,y are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the two Responses,and strictly adhere to the scoring guidelines to provide two accurate scores.**

Now here are the Instruction/Question, the Responses, and your judge result:

Instruction/Question: {question}

Response One: {response1}

Response Two: {response2}

Your Python dictionary containing the two scores:

"""

DOUBLE_10_MATH="""
You are an expert evaluator tasked with assessing the qualities of two Responses to math problems from the GSM8k/MATH dataset in NLP.
You will be provided with an Instruction/Question and two responses generated by different models.


Your task is to evaluate the qualities of two Responses by focusing on the following evaluation criteria:
After carefully analyzing the math problem and deriving a final answer yourself, for each Response, regardless of whether the mathematical reasoning or analysis in the Response is correct or reasonable, or whether the Response contains irrelevant, redundant or repetitive content, your evaluation should focus solely on two possible scenarios (**for each Response, only one of the following two cases applies**):
**(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply search for whether the correct answer to the math Question is mentioned/appears in any of 
these sentences.**
**(Case B) If the Response does not contain any sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply check whether **the LAST single numerical number in the entire Response** is the correct answer (usually a single numerical value) to the math Question.**


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]. Please provide **two precise integer scores between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is not** the correct answer (usually a single numerical value) to the math Question.
2 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **most likely do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response *is most likely not** the correct answer (usually a single numerical value) to the math Question.
3 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (< 40%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely (< 40%) to be** the 
correct answer (usually a single numerical value) to the math Question.
4 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (40%-50%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely (40%-50%) to be** the 
correct answer (usually a single numerical value) to the math Question.
5 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are likely (50%-60%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is likely to be (50%-60%)** the correct answer (usually a single numerical value) to the math Question.
6 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are likely (60%-70%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is likely to be (60%-70%)** the correct answer (usually a single numerical value) to the math Question.
7 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (70%-80%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely (70%-80%) to be** the correct answer (usually a single numerical value) to the math Question.
8 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (80%-90%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely (80%-90%) to be** the correct answer (usually a single numerical value) to the math Question.
9 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (90%-99%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely (90%-99%) to be** the correct answer (usually a single numerical value) to the math Question.
10 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **definitely contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is definitely** the correct answer (usually a single numerical value) to the math Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, Score for the Response Two": y}} where x,y are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the two Responses,and strictly adhere to the scoring guidelines to provide two accurate scores.**


Now here are the Instruction/Question, the Responses, and your judge result:

Instruction/Question: {question}

Response One: {response1}

Response Two: {response2}

Your Python dictionary containing the two scores:

"""

TRIPLE_5_MATH="""
You are an expert evaluator tasked with assessing the qualities of three Responses to math problems from the GSM8k/MATH dataset in NLP.
You will be provided with an Instruction/Question and three responses generated by different models.


Your task is to evaluate the qualities of three Responses  by focusing on the following evaluation criteria:
After carefully analyzing the math problem and deriving a final answer yourself, for each Response, regardless of whether the mathematical reasoning or analysis in the Response is correct or reasonable, or whether the Response contains irrelevant, redundant or repetitive content, your evaluation should focus solely on two possible scenarios (**for each Response, only one of the following two cases applies**):
**(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply search for whether the correct answer to the math Question is mentioned/appears in any of 
these sentences.**
**(Case B) If the Response does not contain any sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply check whether **the LAST single numerical number in the entire Response** is the correct answer (usually a single numerical value) to the math Question.**

In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5]. Please provide **three precise integer scores between [1, 2, 3, 4, 5]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is not** the correct answer (usually a single numerical value) to the math Question.
2 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **most likely do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response *is most likely not** the correct answer (usually a single numerical value) to the math Question.
3 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (20%-60%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely to be (20%-60%)** the correct answer (usually a single numerical value) to the math Question.
4 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (60%-99%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely to be (60%-99%)** the correct answer (usually a single numerical value) to the math Question.
5 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **definitely contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is definitely** the correct answer (usually a single numerical value) to the math Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, Score for the Response Two": y, Score for the Response Three": z}} where x,y,z are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the three Responses,and strictly adhere to the scoring guidelines to provide three accurate scores.**


Now here are the Instruction/Question, the Responses, and your judge result:

Instruction/Question: {question}

Response One: {response1}

Response Two: {response2}

Response Three: {response3}

Your Python dictionary containing the three scores:

"""

TRIPLE_3_MATH="""
You are an expert evaluator tasked with assessing the qualities of three Responses to math problems from the GSM8k/MATH dataset in NLP.
You will be provided with an Instruction/Question and three responses generated by different models.


Your task is to evaluate the qualities of three Responses  by focusing on the following evaluation criteria:
After carefully analyzing the math problem and deriving a final answer yourself, for each Response, regardless of whether the mathematical reasoning or analysis in the Response is correct or reasonable, or whether the Response contains irrelevant, redundant or repetitive content, your evaluation should focus solely on two possible scenarios (**for each Response, only one of the following two cases applies**):
**(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply search for whether the correct answer to the math Question is mentioned/appears in any of 
these sentences.**
**(Case B) If the Response does not contain any sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply check whether **the LAST single numerical number in the entire Response** is the correct answer (usually a single numerical value) to the math Question.**

In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3]. Please provide **three precise integer scores between [1, 2, 3]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer  sentences **do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is not** the correct answer (usually a single numerical value) to the math Question.
2 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer  sentences **seems likely or very likely to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely or very likely to be** the correct answer (usually a single numerical value) to the math Question.
3 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer  sentences **100% contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **100% is** the correct answer (usually a single numerical value) to the math Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, Score for the Response Two": y, Score for the Response Three": z}} where x,y,z are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the three Responses,and strictly adhere to the scoring guidelines to provide three accurate scores.**


Now here are the Instruction/Question, the Responses, and your judge result:

Instruction/Question: {question}

Response One: {response1}

Response Two: {response2}

Response Three: {response3}

Your Python dictionary containing the three scores:

"""

TRIPLE_7_MATH="""
You are an expert evaluator tasked with assessing the qualities of three Responses to math problems from the GSM8k/MATH dataset in NLP.
You will be provided with an Instruction/Question and three responses generated by different models.


Your task is to evaluate the qualities of three Responses  by focusing on the following evaluation criteria:
After carefully analyzing the math problem and deriving a final answer yourself, for each Response, regardless of whether the mathematical reasoning or analysis in the Response is correct or reasonable, or whether the Response contains irrelevant, redundant or repetitive content, your evaluation should focus solely on two possible scenarios (**for each Response, only one of the following two cases applies**):
**(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply search for whether the correct answer to the math Question is mentioned/appears in any of 
these sentences.**
**(Case B) If the Response does not contain any sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply check whether **the LAST single numerical number in the entire Response** is the correct answer (usually a single numerical value) to the math Question.**

In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7]. Please provide **three precise integer scores between  [1, 2, 3, 4, 5, 6, 7]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is not** the correct answer (usually a single numerical value) to the math Question.
2 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **most likely do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response *is most likely not** the correct answer (usually a single numerical value) to the math Question.
3 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (< 40%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely (< 40%) to be ** the correct answer (usually a single numerical value) to the math Question.
4 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (40%-60%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely (40%-60%) to be** the 
5 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are likely (60%-80%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is likely to be (60%-80%)** the correct answer (usually a single numerical value) to the math Question.
6 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (80%-99%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely (80%-99%) to be** the correct answer (usually a single numerical value) to the math Question.
7 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **definitely contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is definitely** the correct answer (usually a single numerical value) to the math Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, Score for the Response Two": y, Score for the Response Three": z}} where x,y,z are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the three Responses,and strictly adhere to the scoring guidelines to provide three accurate scores.**


Now here are the Instruction/Question, the Responses, and your judge result:

Instruction/Question: {question}

Response One: {response1}

Response Two: {response2}

Response Three: {response3}

Your Python dictionary containing the three scores:

"""

TRIPLE_10_MATH="""
You are an expert evaluator tasked with assessing the qualities of three Responses to math problems from the GSM8k/MATH dataset in NLP.
You will be provided with an Instruction/Question and three responses generated by different models.


Your task is to evaluate the qualities of three Responses  by focusing on the following evaluation criteria:
After carefully analyzing the math problem and deriving a final answer yourself, for each Response, regardless of whether the mathematical reasoning or analysis in the Response is correct or reasonable, or whether the Response contains irrelevant, redundant or repetitive content, your evaluation should focus solely on two possible scenarios (**for each Response, only one of the following two cases applies**):
**(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply search for whether the correct answer to the math Question is mentioned/appears in any of 
these sentences.**
**(Case B) If the Response does not contain any sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply check whether **the LAST single numerical number in the entire Response** is the correct answer (usually a single numerical value) to the math Question.**


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]. Please provide **three precise integer scores between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is not** the correct answer (usually a single numerical value) to the math Question.
2 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **most likely do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response *is most likely not** the correct answer (usually a single numerical value) to the math Question.
3 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (< 40%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely (< 40%) to be** the 
correct answer (usually a single numerical value) to the math Question.
4 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (40%-50%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely (40%-50%) to be** the 
correct answer (usually a single numerical value) to the math Question.
5 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are likely (50%-60%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is likely to be (50%-60%)** the correct answer (usually a single numerical value) to the math Question.
6 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are likely (60%-70%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is likely to be (60%-70%)** the correct answer (usually a single numerical value) to the math Question.
7 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (70%-80%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely (70%-80%) to be** the correct answer (usually a single numerical value) to the math Question.
8 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (80%-90%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely (80%-90%) to be** the correct answer (usually a single numerical value) to the math Question.
9 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (90%-99%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely (90%-99%) to be** the correct answer (usually a single numerical value) to the math Question.
10 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **definitely contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is definitely** the correct answer (usually a single numerical value) to the math Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, Score for the Response Two": y, Score for the Response Three": z}} where x,y,z are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the three Responses,and strictly adhere to the scoring guidelines to provide three accurate scores.**


Now here are the Instruction/Question, the Responses, and your judge result:

Instruction/Question: {question}

Response One: {response1}

Response Two: {response2}

Response Three: {response3}

Your Python dictionary containing the three scores:

"""

MULTI_5_MATH="""
You are an expert evaluator tasked with assessing the qualities of four Responses to math problems from the GSM8k/MATH dataset in NLP.
You will be provided with an Instruction/Question and four responses generated by different models.


Your task is to evaluate the qualities of four Responses  by focusing on the following evaluation criteria:
After carefully analyzing the math problem and deriving a final answer yourself, for each Response, regardless of whether the mathematical reasoning or analysis in the Response is correct or reasonable, or whether the Response contains irrelevant, redundant or repetitive content, your evaluation should focus solely on two possible scenarios (**for each Response, only one of the following two cases applies**):
**(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply search for whether the correct answer to the math Question is mentioned/appears in any of 
these sentences.**
**(Case B) If the Response does not contain any sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply check whether **the LAST single numerical number in the entire Response** is the correct answer (usually a single numerical value) to the math Question.**

In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5]. Please provide **four precise integer scores between [1, 2, 3, 4, 5]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is not** the correct answer (usually a single numerical value) to the math Question.
2 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **most likely do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response *is most likely not** the correct answer (usually a single numerical value) to the math Question.
3 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (20%-60%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely to be (20%-60%)** the correct answer (usually a single numerical value) to the math Question.
4 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (60%-99%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely to be (60%-99%)** the correct answer (usually a single numerical value) to the math Question.
5 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **definitely contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is definitely** the correct answer (usually a single numerical value) to the math Question.




Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z, "Score for the Response Four": w}} where x,y,z,w are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the four Responses,and strictly adhere to the scoring guidelines to provide four accurate scores.**


Now here are the Instruction/Question, the Responses, and your judge result:

Instruction/Question: {question}

Response One: {response1}

Response Two: {response2}

Response Three: {response3}

Response Four: {response4}

Your Python dictionary containing the four scores:

"""

MULTI_3_MATH="""
You are an expert evaluator tasked with assessing the qualities of four Responses to math problems from the GSM8k/MATH dataset in NLP.
You will be provided with an Instruction/Question and four responses generated by different models.


Your task is to evaluate the qualities of four Responses  by focusing on the following evaluation criteria:
After carefully analyzing the math problem and deriving a final answer yourself, for each Response, regardless of whether the mathematical reasoning or analysis in the Response is correct or reasonable, or whether the Response contains irrelevant, redundant or repetitive content, your evaluation should focus solely on two possible scenarios (**for each Response, only one of the following two cases applies**):
**(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply search for whether the correct answer to the math Question is mentioned/appears in any of 
these sentences.**
**(Case B) If the Response does not contain any sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply check whether **the LAST single numerical number in the entire Response** is the correct answer (usually a single numerical value) to the math Question.**

In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3]. Please provide **four precise integer scores between [1, 2, 3]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer  sentences **do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is not** the correct answer (usually a single numerical value) to the math Question.
2 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer  sentences **seems likely or very likely to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely or very likely to be** the correct answer (usually a single numerical value) to the math Question.
3 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer  sentences **100% contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **100% is** the correct answer (usually a single numerical value) to the math Question.




Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z, "Score for the Response Four": w}} where x,y,z,w are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the four Responses,and strictly adhere to the scoring guidelines to provide four accurate scores.**


Now here are the Instruction/Question, the Responses, and your judge result:

Instruction/Question: {question}

Response One: {response1}

Response Two: {response2}

Response Three: {response3}

Response Four: {response4}

Your Python dictionary containing the four scores:

"""

MULTI_7_MATH="""
You are an expert evaluator tasked with assessing the qualities of four Responses to math problems from the GSM8k/MATH dataset in NLP.
You will be provided with an Instruction/Question and four responses generated by different models.


Your task is to evaluate the qualities of four Responses  by focusing on the following evaluation criteria:
After carefully analyzing the math problem and deriving a final answer yourself, for each Response, regardless of whether the mathematical reasoning or analysis in the Response is correct or reasonable, or whether the Response contains irrelevant, redundant or repetitive content, your evaluation should focus solely on two possible scenarios (**for each Response, only one of the following two cases applies**):
**(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply search for whether the correct answer to the math Question is mentioned/appears in any of 
these sentences.**
**(Case B) If the Response does not contain any sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply check whether **the LAST single numerical number in the entire Response** is the correct answer (usually a single numerical value) to the math Question.**


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7]. Please provide **four precise integer scores between  [1, 2, 3, 4, 5, 6, 7]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is not** the correct answer (usually a single numerical value) to the math Question.
2 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **most likely do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response *is most likely not** the correct answer (usually a single numerical value) to the math Question.
3 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (< 40%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely (< 40%) to be ** the correct answer (usually a single numerical value) to the math Question.
4 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (40%-60%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely (40%-60%) to be** the 
5 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are likely (60%-80%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is likely to be (60%-80%)** the correct answer (usually a single numerical value) to the math Question.
6 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (80%-99%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely (80%-99%) to be** the correct answer (usually a single numerical value) to the math Question.
7 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **definitely contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is definitely** the correct answer (usually a single numerical value) to the math Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z, "Score for the Response Four": w}} where x,y,z,w are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the four Responses,and strictly adhere to the scoring guidelines to provide four accurate scores.**


Now here are the Instruction/Question, the Responses, and your judge result:

Instruction/Question: {question}

Response One: {response1}

Response Two: {response2}

Response Three: {response3}

Response Four: {response4}

Your Python dictionary containing the four scores:

"""

MULTI_10_MATH="""
You are an expert evaluator tasked with assessing the qualities of four Responses to math problems from the GSM8k/MATH dataset in NLP.
You will be provided with an Instruction/Question and four responses generated by different models.


Your task is to evaluate the qualities of four Responses  by focusing on the following evaluation criteria:
After carefully analyzing the math problem and deriving a final answer yourself, for each Response, regardless of whether the mathematical reasoning or analysis in the Response is correct or reasonable, or whether the Response contains irrelevant, redundant or repetitive content, your evaluation should focus solely on two possible scenarios (**for each Response, only one of the following two cases applies**):
**(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply search for whether the correct answer to the math Question is mentioned/appears in any of 
these sentences.**
**(Case B) If the Response does not contain any sentences containing "the answer is", "The answer is", "answer", or "Answer":
Simply check whether **the LAST single numerical number in the entire Response** is the correct answer (usually a single numerical value) to the math Question.**


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]. Please provide **four precise integer scores between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]** by **strictly and meticulously adhering to the following scoring guidelines**: 
1 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is not** the correct answer (usually a single numerical value) to the math Question.
2 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These answer sentences **most likely do not contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response *is most likely not** the correct answer (usually a single numerical value) to the math Question.
3 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (< 40%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely (< 40%) to be** the 
correct answer (usually a single numerical value) to the math Question.
4 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **seem likely (40%-50%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **seems likely (40%-50%) to be** the 
correct answer (usually a single numerical value) to the math Question.
5 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are likely (50%-60%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is likely to be (50%-60%)** the correct answer (usually a single numerical value) to the math Question.
6 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are likely (60%-70%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is likely to be (60%-70%)** the correct answer (usually a single numerical value) to the math Question.
7 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (70%-80%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely (70%-80%) to be** the correct answer (usually a single numerical value) to the math Question.
8 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (80%-90%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely (80%-90%) to be** the correct answer (usually a single numerical value) to the math Question.
9 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **are highly likely (90%-99%) to contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is highly likely (90%-99%) to be** the correct answer (usually a single numerical value) to the math Question.
10 = Regardless of how irrelevant, unreasonable, or unformatted other content in the Response is: 
(Case A) If the Response contains a sentence/sentences containing "the answer is", "The answer is", "answer", or "Answer":
These  answer sentences **definitely contain** the correct answer (usually a single numerical value) to the math Question.
(Case B) If the Response does not contain any sentence containing "the answer is", "The answer is", "answer", or "Answer":
**The last numerical value** that appears in the entire Response **is definitely** the correct answer (usually a single numerical value) to the math Question.


Note:
1) **Output format: Please return only a Python dictionary in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z, "Score for the Response Four": w}} where x,y,z,w are the placeholders that you should replace with the integer scores for each Response. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Carefully consider the content of the four Responses,and strictly adhere to the scoring guidelines to provide four accurate scores.**


Now here are the Instruction/Question, the Responses, and your judge result:

Instruction/Question: {question}

Response One: {response1}

Response Two: {response2}

Response Three: {response3}

Response Four: {response4}

Your Python dictionary containing the four scores:

"""


# AlpacaEval
SINGLE_5_INST_NEW2="""
You are an expert evaluator tasked with assessing the quality of a Response generated for an Instruction from the well-known instruction-following dataset AlpacaEval in NLP.
You will be provided with an Instruction and a Response generated by a model.
 
Your task is to evaluate the overall quality of the Response by focusing on the following evaluation criteria:
Always keep in mind the "Core Evaluation Criteria"  Evaluate whether the Response effectively addresses the Instruction from a human perspective. Also, please focus on the following **FOUR Specific Evaluation Criteria**:
**Basic Requirement: Understanding the Question & Response Relevance**Does the Response understand and follow the Instruction without going off-topic or irrelevant? 
**Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness**: Does the Response correctly, reasonably, and logically answer the Instruction? Overall, does the Response meet the core requirements of the Instruction in terms of usefulness and effectiveness?
**Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value**: In cases where needed (especially for more open-ended Instructions), does the Response thoroughly cover all aspects of the Instruction's requirements, including all key points, relevant aspects, necessary information, steps for problem-solving needed to perfectly answer the Instruction? Does the Response go beyond surface-level answers and provide valuable, useful, creative, more in-depth information, offering added value and making the response more perfect?
**Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**: Does the Response use appropriate language that is clear, natural, coherent, fluent, concise, and easy to understand? Does the Response avoid vague, unnecessarily verbose, or repetitive statements? 


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5]. Please provide **a precise integer score between [1, 2, 3, 4, 5]** by **strictly and meticulously adhering to the following scoring guidelines**:
**1 = From a human perspective, overall, the Response fails to address the Instructions needs, and it is a "Unrelevant, Unacceptable Response.**
Because: It fails to follow the above Basic Requirement: Understanding the Question & Response Relevance, let alone the more advanced requirements.  
**2 = From a human perspective, overall, the Response "partially addresses the Instructions needs, and it is a Relevant, Useful Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has several obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
**3 = From a human perspective, overall, the Response sufficiently addresses the Instructions needs, and it is a Relevant, Useful, Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  and it  **has minor, subtle shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
**4 = From a human perspective, overall, the Response excellently addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Excellent Response.**
Because: It meets the Basic Requirement: Understanding the Question & Response Relevance, and **there may be minor room for improvement in the following criteria: Core Requirement: Correctness, Reasonableness, Logical Consistency, and overall Usefulness/Effectiveness, Advanced Requirement One (Content-Related): Completeness, Thoroughness, Depth, Creativity, and Added Value, Advanced Requirement Two (Language-Related): Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
**5 = From a human perspective, overall, the Response perfectly addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Perfect Response.** 
Because: It fully excels in all above FOUR Specific Evaluation Criteria, with NO room for improvement.



Note:
1) **Output format: Please return only a Python Dictionary, 100% STRICTLY following in the format {{"Score for the Response": x}} where x is the placeholder that you should replace with the integer score. NOTE: You are NOT allowed to modify the "key" of the Dictionary under any circumstances. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Do NOT allow the length of the responses to influence your evaluation. Carefully consider the content of the Response, and Strictly adhere to the scoring guidelines to provide a precise score.**

Now here are the Instruction, the Response, and your judge result:

Instruction: {question}

Response: {response} 

Your Python Dictionary containing the score:

"""

SINGLE_10_INST_NEW2="""
You are an expert evaluator tasked with assessing the quality of a Response generated for an Instruction from the well-known instruction-following dataset AlpacaEval in NLP.
You will be provided with an Instruction and a Response generated by a model.
 
Your task is to evaluate the overall quality of the Response by focusing on the following evaluation criteria:
Always keep in mind the "Core Evaluation Criteria"  Evaluate whether the Response effectively addresses the Instruction from a human perspective. Also, please focus on the following **FOUR Specific Evaluation Criteria**:
**Basic Requirement: Understanding the Question & Response Relevance**Does the Response understand and follow the Instruction without going off-topic or irrelevant? 
**Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness**: Does the Response correctly, reasonably, and logically answer the Instruction? Overall, does the Response meet the core requirements of the Instruction in terms of usefulness and effectiveness?
**Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value**: In cases where needed (especially for more open-ended Instructions), does the Response thoroughly cover all aspects of the Instruction's requirements, including all key points, relevant aspects, necessary information, steps for problem-solving needed to perfectly answer the Instruction? Does the Response go beyond surface-level answers and provide valuable, useful, creative, more in-depth information, offering added value and making the response more perfect?
**Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**: Does the Response use appropriate language that is clear, natural, coherent, fluent, concise, and easy to understand? Does the Response avoid vague, unnecessarily verbose, or repetitive statements? 


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]. Please provide **a precise integer score between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]** by **strictly and meticulously adhering to the following scoring guidelines**:
**1 = From a human perspective, overall, the Response fails to address the Instructions needs, and it is a "Unrelevant, Unacceptable Response.**
Because: It fails to meet the above Basic Requirement: Understanding the Question & Response Relevance, let alone the more advanced requirements.  

**2 = From a human perspective, overall, the Response "partially addresses the Instructions needs to a small extent, and it is a Relevant, Low-Utility Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has too many serious and obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**3 = From a human perspective, overall, the Response "partially addresses the Instructions needs to a moderate extent, and it is a Relevant, Moderately Useful Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has several serious and obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**4 = From a human perspective, overall, the Response "partially addresses the Instructions needs to a large extent, and it is a Relevant, Useful Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has several obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**5 = From a human perspective, overall, the Response almost addresses the Instructions needs, and it is a Relevant, Useful, Minimally Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has noticeable shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**6 = From a human perspective, overall, the Response sufficiently addresses the Instructions needs, and it is a Relevant, Useful, Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  and it  **has minor, subtle shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**7 = From a human perspective, overall, the Response effectively addresses the Instructions needs, and it is a Relevant, Useful, Acceptable, Good Response.**
Because: It meets the Basic Requirement: Understanding the Question & Response Relevance, and **there may be minor room for improvement in the following criteria: Core Requirement: Correctness, Reasonableness, Logical Consistency, and overall Usefulness/Effectiveness, Advanced Requirement One (Content-Related): Completeness, Thoroughness, Depth, Creativity, and Added Value, Advanced Requirement Two (Language-Related): Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**8 = From a human perspective, overall, the Response excellently addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Excellent Response.**
Because: It excels in all FOUR Specific Evaluation Criteria, and there seems to be no room for improvement.

**9 = From a human perspective, overall, the Response perfectly addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Perfect Response.** 
Because: It fully excels in all above FOUR Specific Evaluation Criteria, with NO room for improvement.

**10 = From a human perspective, overall, the Response exceeds expectations and very perfectly addresses the Instructions needs, and it is a Relevant, Useful, Very Strong Acceptable, Very Perfect Response.**
Because: It fully excels in all above FOUR Specific Evaluation Criteria, with NO room for improvement.

 


Note:
1) **Output format: Please return only a Python Dictionary, 100% STRICTLY following in the format {{"Score for the Response": x}} where x is the placeholder that you should replace with the integer score. NOTE: You are NOT allowed to modify the "key" of the Dictionary under any circumstances. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Do NOT allow the length of the responses to influence your evaluation. Carefully consider the content of the Response, and Strictly adhere to the scoring guidelines to provide a precise score.**

Now here are the Instruction, the Response, and your judge result:

Instruction: {question}

Response: {response} 

Your Python Dictionary containing the score:

"""

SINGLE_3_INST_NEW2="""
You are an expert evaluator tasked with assessing the quality of a Response generated for an Instruction from the well-known instruction-following dataset AlpacaEval in NLP.
You will be provided with an Instruction and a Response generated by a model.
 
Your task is to evaluate the overall quality of the Response by focusing on the following evaluation criteria:
Always keep in mind the "Core Evaluation Criteria"  Evaluate whether the Response effectively addresses the Instruction from a human perspective. Also, please focus on the following **FOUR Specific Evaluation Criteria**:
**Basic Requirement: Understanding the Question & Response Relevance**Does the Response understand and follow the Instruction without going off-topic or irrelevant? 
**Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness**: Does the Response correctly, reasonably, and logically answer the Instruction? Overall, does the Response meet the core requirements of the Instruction in terms of usefulness and effectiveness?
**Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value**: In cases where needed (especially for more open-ended Instructions), does the Response thoroughly cover all aspects of the Instruction's requirements, including all key points, relevant aspects, necessary information, steps for problem-solving needed to perfectly answer the Instruction? Does the Response go beyond surface-level answers and provide valuable, useful, creative, more in-depth information, offering added value and making the response more perfect?
**Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**: Does the Response use appropriate language that is clear, natural, coherent, fluent, concise, and easy to understand? Does the Response avoid vague, unnecessarily verbose, or repetitive statements? 


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3]. Please provide **a precise integer score between [1, 2, 3]** by **strictly and meticulously adhering to the following scoring guidelines**:
**1 = From a human perspective, overall, the Response fails to address Instructions needs or partially addresses the Instructions needs, and it is a Unacceptable Response.**
Because: It fails to meet the above Basic Requirement: Understanding the Question & Response Relevance, let alone the more advanced requirements; or, it meets the above Basic Requirement: Understanding the Question & Response Relevance,  but **has several obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**. 
**2 = From a human perspective, overall, the Response sufficiently addresses the Instructions needs, and it is a Relevant, Useful, Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  and it  **has minor, subtle shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
**3 = From a human perspective, overall, the Response excellently or perfectly addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Excellent Response.**
Because: It meets the Basic Requirement: Understanding the Question & Response Relevance, and **there may be no room for improvement in the following criteria: Core Requirement: Correctness, Reasonableness, Logical Consistency, and overall Usefulness/Effectiveness, Advanced Requirement One (Content-Related): Completeness, Thoroughness, Depth, Creativity, and Added Value, Advanced Requirement Two (Language-Related): Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.



Note:
1) **Output format: Please return only a Python Dictionary, 100% STRICTLY following in the format {{"Score for the Response": x}} where x is the placeholder that you should replace with the integer score. NOTE: You are NOT allowed to modify the "key" of the Dictionary under any circumstances. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Do NOT allow the length of the responses to influence your evaluation. Carefully consider the content of the Response, and Strictly adhere to the scoring guidelines to provide a precise score.**

Now here are the Instruction, the Response, and your judge result:

Instruction: {question}

Response: {response} 

Your Python Dictionary containing the score:

"""

SINGLE_7_INST_NEW2="""
You are an expert evaluator tasked with assessing the quality of a Response generated for an Instruction from the well-known instruction-following dataset AlpacaEval in NLP.
You will be provided with an Instruction and a Response generated by a model.
 
Your task is to evaluate the overall quality of the Response by focusing on the following evaluation criteria:
Always keep in mind the "Core Evaluation Criteria"  Evaluate whether the Response effectively addresses the Instruction from a human perspective. Also, please focus on the following **FOUR Specific Evaluation Criteria**:
**Basic Requirement: Understanding the Question & Response Relevance**Does the Response understand and follow the Instruction without going off-topic or irrelevant? 
**Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness**: Does the Response correctly, reasonably, and logically answer the Instruction? Overall, does the Response meet the core requirements of the Instruction in terms of usefulness and effectiveness?
**Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value**: In cases where needed (especially for more open-ended Instructions), does the Response thoroughly cover all aspects of the Instruction's requirements, including all key points, relevant aspects, necessary information, steps for problem-solving needed to perfectly answer the Instruction? Does the Response go beyond surface-level answers and provide valuable, useful, creative, more in-depth information, offering added value and making the response more perfect?
**Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**: Does the Response use appropriate language that is clear, natural, coherent, fluent, concise, and easy to understand? Does the Response avoid vague, unnecessarily verbose, or repetitive statements? 


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7]. Please provide **a precise integer score between [1, 2, 3, 4, 5, 6, 7]** by **strictly and meticulously adhering to the following scoring guidelines**:
**1 = From a human perspective, overall, the Response fails to address the Instructions needs, and it is a "Unrelevant, Unacceptable Response.**
Because: It fails to follow the above Basic Requirement: Understanding the Question & Response Relevance, let alone the more advanced requirements.  

**2 = From a human perspective, overall, the Response "partially addresses the Instructions needs, and it is a Relevant, Useful Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has several obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**3 = From a human perspective, overall, the Response almost addresses the Instructions needs, and it is a Relevant, Useful, Minimally Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has noticeable shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**4 = From a human perspective, overall, the Response sufficiently addresses the Instructions needs, and it is a Relevant, Useful, Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  and it  **has minor, subtle shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**5 = From a human perspective, overall, the Response effectively addresses the Instructions needs, and it is a Relevant, Useful, Acceptable, Good Response.**
Because: It meets the Basic Requirement: Understanding the Question & Response Relevance, and **there may be minor room for improvement in the following criteria: Core Requirement: Correctness, Reasonableness, Logical Consistency, and overall Usefulness/Effectiveness, Advanced Requirement One (Content-Related): Completeness, Thoroughness, Depth, Creativity, and Added Value, Advanced Requirement Two (Language-Related): Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**6 = From a human perspective, overall, the Response excellently addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Excellent Response.**
Because: It excels in all FOUR Specific Evaluation Criteria, and there seems to be no room for improvement.

**7 = From a human perspective, overall, the Response perfectly addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Perfect Response.** 
Because: It fully excels in all above FOUR Specific Evaluation Criteria, with NO room for improvement.



Note:
1) **Output format: Please return only a Python Dictionary, 100% STRICTLY following in the format {{"Score for the Response": x}} where x is the placeholder that you should replace with the integer score. NOTE: You are NOT allowed to modify the "key" of the Dictionary under any circumstances. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Do NOT allow the length of the responses to influence your evaluation. Carefully consider the content of the Response, and Strictly adhere to the scoring guidelines to provide a precise score.**

Now here are the Instruction, the Response, and your judge result:

Instruction: {question}

Response: {response} 

Your Python Dictionary containing the score:

"""

DOUBLE_5_INST_NEW2="""
You are an expert evaluator tasked with assessing the qualities of two Responses generated for an Instruction from the well-known instruction-following dataset AlpacaEval in NLP.
You will be provided with an Instruction and two Responses generated by different models.
 
Your task is to evaluate the overall qualities of two Responses by focusing on the following evaluation criteria:
Always keep in mind the "Core Evaluation Criteria"  Evaluate whether the Response effectively addresses the Instruction from a human perspective. Also, please focus on the following **FOUR Specific Evaluation Criteria**:
**Basic Requirement: Understanding the Question & Response Relevance**Does the Response understand and follow the Instruction without going off-topic or irrelevant? 
**Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness**: Does the Response correctly, reasonably, and logically answer the Instruction? Overall, does the Response meet the core requirements of the Instruction in terms of usefulness and effectiveness?
**Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value**: In cases where needed (especially for more open-ended Instructions), does the Response thoroughly cover all aspects of the Instruction's requirements, including all key points, relevant aspects, necessary information, steps for problem-solving needed to perfectly answer the Instruction? Does the Response go beyond surface-level answers and provide valuable, useful, creative, more in-depth information, offering added value and making the response more perfect?
**Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**: Does the Response use appropriate language that is clear, natural, coherent, fluent, concise, and easy to understand? Does the Response avoid vague, unnecessarily verbose, or repetitive statements? 


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5]. Please provide **two precise integer scores between [1, 2, 3, 4, 5]** by **strictly and meticulously adhering to the following scoring guidelines**:
**1 = From a human perspective, overall, the Response fails to address the Instructions needs, and it is a "Unrelevant, Unacceptable Response.**
Because: It fails to follow the above Basic Requirement: Understanding the Question & Response Relevance, let alone the more advanced requirements.  
**2 = From a human perspective, overall, the Response "partially addresses the Instructions needs, and it is a Relevant, Useful Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has several obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
**3 = From a human perspective, overall, the Response sufficiently addresses the Instructions needs, and it is a Relevant, Useful, Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  and it  **has minor, subtle shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
**4 = From a human perspective, overall, the Response excellently addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Excellent Response.**
Because: It meets the Basic Requirement: Understanding the Question & Response Relevance, and **there may be minor room for improvement in the following criteria: Core Requirement: Correctness, Reasonableness, Logical Consistency, and overall Usefulness/Effectiveness, Advanced Requirement One (Content-Related): Completeness, Thoroughness, Depth, Creativity, and Added Value, Advanced Requirement Two (Language-Related): Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
**5 = From a human perspective, overall, the Response perfectly addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Perfect Response.** 
Because: It fully excels in all above FOUR Specific Evaluation Criteria, with NO room for improvement.

 
Note:
1) **Output format: Please return only a Python Dictionary, 100% STRICTLY following in the format {{"Score for the Response One": x, "Score for the Response Two": y}} where x,y are the placeholders that you should replace with the integer scores for each Response. NOTE: You are NOT allowed to modify the "key" of the Dictionary under any circumstances. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Do NOT allow the length of the responses to influence your evaluation. Carefully consider the content of the two Responses, and strictly adhere to the scoring guidelines to provide two precise scores.**


Now here are the Instruction, the Responses, and your judge result:

Instruction: {question}

Response One: {response1} 

Response Two: {response2} 

Your Python Dictionary containing the two scores:

"""

DOUBLE_10_INST_NEW2="""
You are an expert evaluator tasked with assessing the qualities of two Responses generated for an Instruction from the well-known instruction-following dataset AlpacaEval in NLP.
You will be provided with an Instruction and two Responses generated by different models.
 
Your task is to evaluate the overall qualities of two Responses by focusing on the following evaluation criteria:
Always keep in mind the "Core Evaluation Criteria"  Evaluate whether the Response effectively addresses the Instruction from a human perspective. Also, please focus on the following **FOUR Specific Evaluation Criteria**:
**Basic Requirement: Understanding the Question & Response Relevance**Does the Response understand and follow the Instruction without going off-topic or irrelevant? 
**Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness**: Does the Response correctly, reasonably, and logically answer the Instruction? Overall, does the Response meet the core requirements of the Instruction in terms of usefulness and effectiveness?
**Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value**: In cases where needed (especially for more open-ended Instructions), does the Response thoroughly cover all aspects of the Instruction's requirements, including all key points, relevant aspects, necessary information, steps for problem-solving needed to perfectly answer the Instruction? Does the Response go beyond surface-level answers and provide valuable, useful, creative, more in-depth information, offering added value and making the response more perfect?
**Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**: Does the Response use appropriate language that is clear, natural, coherent, fluent, concise, and easy to understand? Does the Response avoid vague, unnecessarily verbose, or repetitive statements? 


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]. Please provide **two precise integer scores between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]** by **strictly and meticulously adhering to the following scoring guidelines**:
**1 = From a human perspective, overall, the Response fails to address the Instructions needs, and it is a "Unrelevant, Unacceptable Response.**
Because: It fails to meet the above Basic Requirement: Understanding the Question & Response Relevance, let alone the more advanced requirements.  

**2 = From a human perspective, overall, the Response "partially addresses the Instructions needs to a small extent, and it is a Relevant, Low-Utility Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has too many serious and obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**3 = From a human perspective, overall, the Response "partially addresses the Instructions needs to a moderate extent, and it is a Relevant, Moderately Useful Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has several serious and obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**4 = From a human perspective, overall, the Response "partially addresses the Instructions needs to a large extent, and it is a Relevant, Useful Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has several obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**5 = From a human perspective, overall, the Response almost addresses the Instructions needs, and it is a Relevant, Useful, Minimally Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has noticeable shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**6 = From a human perspective, overall, the Response sufficiently addresses the Instructions needs, and it is a Relevant, Useful, Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  and it  **has minor, subtle shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**7 = From a human perspective, overall, the Response effectively addresses the Instructions needs, and it is a Relevant, Useful, Acceptable, Good Response.**
Because: It meets the Basic Requirement: Understanding the Question & Response Relevance, and **there may be minor room for improvement in the following criteria: Core Requirement: Correctness, Reasonableness, Logical Consistency, and overall Usefulness/Effectiveness, Advanced Requirement One (Content-Related): Completeness, Thoroughness, Depth, Creativity, and Added Value, Advanced Requirement Two (Language-Related): Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**8 = From a human perspective, overall, the Response excellently addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Excellent Response.**
Because: It excels in all FOUR Specific Evaluation Criteria, and there seems to be no room for improvement.

**9 = From a human perspective, overall, the Response perfectly addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Perfect Response.** 
Because: It fully excels in all above FOUR Specific Evaluation Criteria, with NO room for improvement.

**10 = From a human perspective, overall, the Response exceeds expectations and very perfectly addresses the Instructions needs, and it is a Relevant, Useful, Very Strong Acceptable, Very Perfect Response.**
Because: It fully excels in all above FOUR Specific Evaluation Criteria, with NO room for improvement.

 
Note:
1) **Output format: Please return only a Python Dictionary, 100% STRICTLY following in the format {{"Score for the Response One": x, "Score for the Response Two": y}} where x,y are the placeholders that you should replace with the integer scores for each Response. NOTE: You are NOT allowed to modify the "key" of the Dictionary under any circumstances. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Do NOT allow the length of the responses to influence your evaluation. Carefully consider the content of the two Responses, and strictly adhere to the scoring guidelines to provide two precise scores.**


Now here are the Instruction, the Responses, and your judge result:

Instruction: {question}

Response One: {response1} 

Response Two: {response2} 

Your Python Dictionary containing the two scores:

"""

DOUBLE_3_INST_NEW2="""
You are an expert evaluator tasked with assessing the qualities of two Responses generated for an Instruction from the well-known instruction-following dataset AlpacaEval in NLP.
You will be provided with an Instruction and two Responses generated by different models.
 
Your task is to evaluate the overall qualities of two Responses by focusing on the following evaluation criteria:
Always keep in mind the "Core Evaluation Criteria"  Evaluate whether the Response effectively addresses the Instruction from a human perspective. Also, please focus on the following **FOUR Specific Evaluation Criteria**:
**Basic Requirement: Understanding the Question & Response Relevance**Does the Response understand and follow the Instruction without going off-topic or irrelevant? 
**Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness**: Does the Response correctly, reasonably, and logically answer the Instruction? Overall, does the Response meet the core requirements of the Instruction in terms of usefulness and effectiveness?
**Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value**: In cases where needed (especially for more open-ended Instructions), does the Response thoroughly cover all aspects of the Instruction's requirements, including all key points, relevant aspects, necessary information, steps for problem-solving needed to perfectly answer the Instruction? Does the Response go beyond surface-level answers and provide valuable, useful, creative, more in-depth information, offering added value and making the response more perfect?
**Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**: Does the Response use appropriate language that is clear, natural, coherent, fluent, concise, and easy to understand? Does the Response avoid vague, unnecessarily verbose, or repetitive statements? 


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3]. Please provide **two precise integer scores between [1, 2, 3]** by **strictly and meticulously adhering to the following scoring guidelines**:
**1 = From a human perspective, overall, the Response fails to address Instructions needs or partially addresses the Instructions needs, and it is a Unacceptable Response.**
Because: It fails to meet the above Basic Requirement: Understanding the Question & Response Relevance, let alone the more advanced requirements; or, it meets the above Basic Requirement: Understanding the Question & Response Relevance,  but **has several obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**. 
**2 = From a human perspective, overall, the Response sufficiently addresses the Instructions needs, and it is a Relevant, Useful, Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  and it  **has minor, subtle shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
**3 = From a human perspective, overall, the Response excellently or perfectly addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Excellent Response.**
Because: It meets the Basic Requirement: Understanding the Question & Response Relevance, and **there may be no room for improvement in the following criteria: Core Requirement: Correctness, Reasonableness, Logical Consistency, and overall Usefulness/Effectiveness, Advanced Requirement One (Content-Related): Completeness, Thoroughness, Depth, Creativity, and Added Value, Advanced Requirement Two (Language-Related): Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
 

Note:
1) **Output format: Please return only a Python Dictionary, 100% STRICTLY following in the format {{"Score for the Response One": x, "Score for the Response Two": y}} where x,y are the placeholders that you should replace with the integer scores for each Response. NOTE: You are NOT allowed to modify the "key" of the Dictionary under any circumstances. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Do NOT allow the length of the responses to influence your evaluation. Carefully consider the content of the two Responses, and strictly adhere to the scoring guidelines to provide two precise scores.**


Now here are the Instruction, the Responses, and your judge result:

Instruction: {question}

Response One: {response1} 

Response Two: {response2} 

Your Python Dictionary containing the two scores:

"""

DOUBLE_7_INST_NEW2="""
You are an expert evaluator tasked with assessing the qualities of two Responses generated for an Instruction from the well-known instruction-following dataset AlpacaEval in NLP.
You will be provided with an Instruction and two Responses generated by different models.
 
Your task is to evaluate the overall qualities of two Responses by focusing on the following evaluation criteria:
Always keep in mind the "Core Evaluation Criteria"  Evaluate whether the Response effectively addresses the Instruction from a human perspective. Also, please focus on the following **FOUR Specific Evaluation Criteria**:
**Basic Requirement: Understanding the Question & Response Relevance**Does the Response understand and follow the Instruction without going off-topic or irrelevant? 
**Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness**: Does the Response correctly, reasonably, and logically answer the Instruction? Overall, does the Response meet the core requirements of the Instruction in terms of usefulness and effectiveness?
**Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value**: In cases where needed (especially for more open-ended Instructions), does the Response thoroughly cover all aspects of the Instruction's requirements, including all key points, relevant aspects, necessary information, steps for problem-solving needed to perfectly answer the Instruction? Does the Response go beyond surface-level answers and provide valuable, useful, creative, more in-depth information, offering added value and making the response more perfect?
**Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**: Does the Response use appropriate language that is clear, natural, coherent, fluent, concise, and easy to understand? Does the Response avoid vague, unnecessarily verbose, or repetitive statements? 


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7]. Please provide **two precise integer scores between [1, 2, 3, 4, 5, 6, 7]** by **strictly and meticulously adhering to the following scoring guidelines**:
**1 = From a human perspective, overall, the Response fails to address the Instructions needs, and it is a "Unrelevant, Unacceptable Response.**
Because: It fails to follow the above Basic Requirement: Understanding the Question & Response Relevance, let alone the more advanced requirements.  

**2 = From a human perspective, overall, the Response "partially addresses the Instructions needs, and it is a Relevant, Useful Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has several obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**3 = From a human perspective, overall, the Response almost addresses the Instructions needs, and it is a Relevant, Useful, Minimally Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has noticeable shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**4 = From a human perspective, overall, the Response sufficiently addresses the Instructions needs, and it is a Relevant, Useful, Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  and it  **has minor, subtle shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**5 = From a human perspective, overall, the Response effectively addresses the Instructions needs, and it is a Relevant, Useful, Acceptable, Good Response.**
Because: It meets the Basic Requirement: Understanding the Question & Response Relevance, and **there may be minor room for improvement in the following criteria: Core Requirement: Correctness, Reasonableness, Logical Consistency, and overall Usefulness/Effectiveness, Advanced Requirement One (Content-Related): Completeness, Thoroughness, Depth, Creativity, and Added Value, Advanced Requirement Two (Language-Related): Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**6 = From a human perspective, overall, the Response excellently addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Excellent Response.**
Because: It excels in all FOUR Specific Evaluation Criteria, and there seems to be no room for improvement.

**7 = From a human perspective, overall, the Response perfectly addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Perfect Response.** 
Because: It fully excels in all above FOUR Specific Evaluation Criteria, with NO room for improvement.



Note:
1) **Output format: Please return only a Python Dictionary, 100% STRICTLY following in the format {{"Score for the Response One": x, "Score for the Response Two": y}} where x,y are the placeholders that you should replace with the integer scores for each Response. NOTE: You are NOT allowed to modify the "key" of the Dictionary under any circumstances. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Do NOT allow the length of the responses to influence your evaluation. Carefully consider the content of the two Responses, and strictly adhere to the scoring guidelines to provide two precise scores.**


Now here are the Instruction, the Responses, and your judge result:

Instruction: {question}

Response One: {response1} 

Response Two: {response2} 

Your Python Dictionary containing the two scores:
"""

TRIPLE_5_INST_NEW2="""
You are an expert evaluator tasked with assessing the qualities of three Responses generated for an Instruction from the well-known instruction-following dataset AlpacaEval in NLP.
You will be provided with an Instruction and three Responses generated by different models.
 
Your task is to evaluate the overall qualities of three Responses by focusing on the following evaluation criteria:
Always keep in mind the "Core Evaluation Criteria"  Evaluate whether the Response effectively addresses the Instruction from a human perspective. Also, please focus on the following **FOUR Specific Evaluation Criteria**:
**Basic Requirement: Understanding the Question & Response Relevance**Does the Response understand and follow the Instruction without going off-topic or irrelevant? 
**Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness**: Does the Response correctly, reasonably, and logically answer the Instruction? Overall, does the Response meet the core requirements of the Instruction in terms of usefulness and effectiveness?
**Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value**: In cases where needed (especially for more open-ended Instructions), does the Response thoroughly cover all aspects of the Instruction's requirements, including all key points, relevant aspects, necessary information, steps for problem-solving needed to perfectly answer the Instruction? Does the Response go beyond surface-level answers and provide valuable, useful, creative, more in-depth information, offering added value and making the response more perfect?
**Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**: Does the Response use appropriate language that is clear, natural, coherent, fluent, concise, and easy to understand? Does the Response avoid vague, unnecessarily verbose, or repetitive statements? 


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5]. Please provide **three precise integer scores between [1, 2, 3, 4, 5]** by **strictly and meticulously adhering to the following scoring guidelines**:
**1 = From a human perspective, overall, the Response fails to address the Instructions needs, and it is a "Unrelevant, Unacceptable Response.**
Because: It fails to follow the above Basic Requirement: Understanding the Question & Response Relevance, let alone the more advanced requirements.  
**2 = From a human perspective, overall, the Response "partially addresses the Instructions needs, and it is a Relevant, Useful Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has several obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
**3 = From a human perspective, overall, the Response sufficiently addresses the Instructions needs, and it is a Relevant, Useful, Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  and it  **has minor, subtle shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
**4 = From a human perspective, overall, the Response excellently addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Excellent Response.**
Because: It meets the Basic Requirement: Understanding the Question & Response Relevance, and **there may be minor room for improvement in the following criteria: Core Requirement: Correctness, Reasonableness, Logical Consistency, and overall Usefulness/Effectiveness, Advanced Requirement One (Content-Related): Completeness, Thoroughness, Depth, Creativity, and Added Value, Advanced Requirement Two (Language-Related): Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
**5 = From a human perspective, overall, the Response perfectly addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Perfect Response.** 
Because: It fully excels in all above FOUR Specific Evaluation Criteria, with NO room for improvement.

 
Note:
1) **Output format: Please return only a Python Dictionary, 100% STRICTLY following in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z}} where x,y,z are the placeholders that you should replace with the integer scores for each Response. NOTE: You are NOT allowed to modify the "key" of the Dictionary under any circumstances. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Do NOT allow the length of the responses to influence your evaluation. Carefully consider the content of the three Responses, and strictly adhere to the scoring guidelines to provide three precise scores.**


Now here are the Instruction, the Responses, and your judge result:

Instruction: {question}

Response One: {response1} 

Response Two: {response2} 

Response Three: {response3} 

Your Python dictionary containing the three scores:

"""

TRIPLE_10_INST_NEW2="""
You are an expert evaluator tasked with assessing the qualities of three Responses generated for an Instruction from the well-known instruction-following dataset AlpacaEval in NLP.
You will be provided with an Instruction and three Responses generated by different models.
 
Your task is to evaluate the overall qualities of three Responses by focusing on the following evaluation criteria:
Always keep in mind the "Core Evaluation Criteria"  Evaluate whether the Response effectively addresses the Instruction from a human perspective. Also, please focus on the following **FOUR Specific Evaluation Criteria**:
**Basic Requirement: Understanding the Question & Response Relevance**Does the Response understand and follow the Instruction without going off-topic or irrelevant? 
**Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness**: Does the Response correctly, reasonably, and logically answer the Instruction? Overall, does the Response meet the core requirements of the Instruction in terms of usefulness and effectiveness?
**Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value**: In cases where needed (especially for more open-ended Instructions), does the Response thoroughly cover all aspects of the Instruction's requirements, including all key points, relevant aspects, necessary information, steps for problem-solving needed to perfectly answer the Instruction? Does the Response go beyond surface-level answers and provide valuable, useful, creative, more in-depth information, offering added value and making the response more perfect?
**Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**: Does the Response use appropriate language that is clear, natural, coherent, fluent, concise, and easy to understand? Does the Response avoid vague, unnecessarily verbose, or repetitive statements? 


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]. Please provide **three precise integer scores between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]** by **strictly and meticulously adhering to the following scoring guidelines**:
**1 = From a human perspective, overall, the Response fails to address the Instructions needs, and it is a "Unrelevant, Unacceptable Response.**
Because: It fails to meet the above Basic Requirement: Understanding the Question & Response Relevance, let alone the more advanced requirements.  

**2 = From a human perspective, overall, the Response "partially addresses the Instructions needs to a small extent, and it is a Relevant, Low-Utility Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has too many serious and obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**3 = From a human perspective, overall, the Response "partially addresses the Instructions needs to a moderate extent, and it is a Relevant, Moderately Useful Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has several serious and obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**4 = From a human perspective, overall, the Response "partially addresses the Instructions needs to a large extent, and it is a Relevant, Useful Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has several obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**5 = From a human perspective, overall, the Response almost addresses the Instructions needs, and it is a Relevant, Useful, Minimally Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has noticeable shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**6 = From a human perspective, overall, the Response sufficiently addresses the Instructions needs, and it is a Relevant, Useful, Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  and it  **has minor, subtle shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**7 = From a human perspective, overall, the Response effectively addresses the Instructions needs, and it is a Relevant, Useful, Acceptable, Good Response.**
Because: It meets the Basic Requirement: Understanding the Question & Response Relevance, and **there may be minor room for improvement in the following criteria: Core Requirement: Correctness, Reasonableness, Logical Consistency, and overall Usefulness/Effectiveness, Advanced Requirement One (Content-Related): Completeness, Thoroughness, Depth, Creativity, and Added Value, Advanced Requirement Two (Language-Related): Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**8 = From a human perspective, overall, the Response excellently addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Excellent Response.**
Because: It excels in all FOUR Specific Evaluation Criteria, and there seems to be no room for improvement.

**9 = From a human perspective, overall, the Response perfectly addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Perfect Response.** 
Because: It fully excels in all above FOUR Specific Evaluation Criteria, with NO room for improvement.

**10 = From a human perspective, overall, the Response exceeds expectations and very perfectly addresses the Instructions needs, and it is a Relevant, Useful, Very Strong Acceptable, Very Perfect Response.**
Because: It fully excels in all above FOUR Specific Evaluation Criteria, with NO room for improvement.

 
Note:
1) **Output format: Please return only a Python Dictionary, 100% STRICTLY following in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z}} where x,y,z are the placeholders that you should replace with the integer scores for each Response. NOTE: You are NOT allowed to modify the "key" of the Dictionary under any circumstances. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Do NOT allow the length of the responses to influence your evaluation. Carefully consider the content of the three Responses, and strictly adhere to the scoring guidelines to provide three precise scores.**


Now here are the Instruction, the Responses, and your judge result:

Instruction: {question}

Response One: {response1} 

Response Two: {response2} 

Response Three: {response3} 

Your Python dictionary containing the three scores:

"""

TRIPLE_3_INST_NEW2="""
You are an expert evaluator tasked with assessing the qualities of three Responses generated for an Instruction from the well-known instruction-following dataset AlpacaEval in NLP.
You will be provided with an Instruction and three Responses generated by different models.
 
Your task is to evaluate the overall qualities of three Responses by focusing on the following evaluation criteria:
Always keep in mind the "Core Evaluation Criteria"  Evaluate whether the Response effectively addresses the Instruction from a human perspective. Also, please focus on the following **FOUR Specific Evaluation Criteria**:
**Basic Requirement: Understanding the Question & Response Relevance**Does the Response understand and follow the Instruction without going off-topic or irrelevant? 
**Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness**: Does the Response correctly, reasonably, and logically answer the Instruction? Overall, does the Response meet the core requirements of the Instruction in terms of usefulness and effectiveness?
**Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value**: In cases where needed (especially for more open-ended Instructions), does the Response thoroughly cover all aspects of the Instruction's requirements, including all key points, relevant aspects, necessary information, steps for problem-solving needed to perfectly answer the Instruction? Does the Response go beyond surface-level answers and provide valuable, useful, creative, more in-depth information, offering added value and making the response more perfect?
**Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**: Does the Response use appropriate language that is clear, natural, coherent, fluent, concise, and easy to understand? Does the Response avoid vague, unnecessarily verbose, or repetitive statements? 


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3]. Please provide **three precise integer scores between [1, 2, 3]** by **strictly and meticulously adhering to the following scoring guidelines**:
**1 = From a human perspective, overall, the Response fails to address Instructions needs or partially addresses the Instructions needs, and it is a Unacceptable Response.**
Because: It fails to meet the above Basic Requirement: Understanding the Question & Response Relevance, let alone the more advanced requirements; or, it meets the above Basic Requirement: Understanding the Question & Response Relevance,  but **has several obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**. 
**2 = From a human perspective, overall, the Response sufficiently addresses the Instructions needs, and it is a Relevant, Useful, Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  and it  **has minor, subtle shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
**3 = From a human perspective, overall, the Response excellently or perfectly addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Excellent Response.**
Because: It meets the Basic Requirement: Understanding the Question & Response Relevance, and **there may be no room for improvement in the following criteria: Core Requirement: Correctness, Reasonableness, Logical Consistency, and overall Usefulness/Effectiveness, Advanced Requirement One (Content-Related): Completeness, Thoroughness, Depth, Creativity, and Added Value, Advanced Requirement Two (Language-Related): Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.


Note:
1) **Output format: Please return only a Python Dictionary, 100% STRICTLY following in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z}} where x,y,z are the placeholders that you should replace with the integer scores for each Response. NOTE: You are NOT allowed to modify the "key" of the Dictionary under any circumstances. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Do NOT allow the length of the responses to influence your evaluation. Carefully consider the content of the three Responses, and strictly adhere to the scoring guidelines to provide three precise scores.**


Now here are the Instruction, the Responses, and your judge result:

Instruction: {question}

Response One: {response1} 

Response Two: {response2} 

Response Three: {response3} 

Your Python dictionary containing the three scores:

"""

TRIPLE_7_INST_NEW2="""
You are an expert evaluator tasked with assessing the qualities of three Responses generated for an Instruction from the well-known instruction-following dataset AlpacaEval in NLP.
You will be provided with an Instruction and three Responses generated by different models.
 
Your task is to evaluate the overall qualities of three Responses by focusing on the following evaluation criteria:
Always keep in mind the "Core Evaluation Criteria"  Evaluate whether the Response effectively addresses the Instruction from a human perspective. Also, please focus on the following **FOUR Specific Evaluation Criteria**:
**Basic Requirement: Understanding the Question & Response Relevance**Does the Response understand and follow the Instruction without going off-topic or irrelevant? 
**Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness**: Does the Response correctly, reasonably, and logically answer the Instruction? Overall, does the Response meet the core requirements of the Instruction in terms of usefulness and effectiveness?
**Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value**: In cases where needed (especially for more open-ended Instructions), does the Response thoroughly cover all aspects of the Instruction's requirements, including all key points, relevant aspects, necessary information, steps for problem-solving needed to perfectly answer the Instruction? Does the Response go beyond surface-level answers and provide valuable, useful, creative, more in-depth information, offering added value and making the response more perfect?
**Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**: Does the Response use appropriate language that is clear, natural, coherent, fluent, concise, and easy to understand? Does the Response avoid vague, unnecessarily verbose, or repetitive statements? 


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7]. Please provide **three precise integer scores between [1, 2, 3, 4, 5, 6, 7]** by **strictly and meticulously adhering to the following scoring guidelines**:
**1 = From a human perspective, overall, the Response fails to address the Instructions needs, and it is a "Unrelevant, Unacceptable Response.**
Because: It fails to follow the above Basic Requirement: Understanding the Question & Response Relevance, let alone the more advanced requirements.  

**2 = From a human perspective, overall, the Response "partially addresses the Instructions needs, and it is a Relevant, Useful Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has several obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**3 = From a human perspective, overall, the Response almost addresses the Instructions needs, and it is a Relevant, Useful, Minimally Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has noticeable shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**4 = From a human perspective, overall, the Response sufficiently addresses the Instructions needs, and it is a Relevant, Useful, Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  and it  **has minor, subtle shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**5 = From a human perspective, overall, the Response effectively addresses the Instructions needs, and it is a Relevant, Useful, Acceptable, Good Response.**
Because: It meets the Basic Requirement: Understanding the Question & Response Relevance, and **there may be minor room for improvement in the following criteria: Core Requirement: Correctness, Reasonableness, Logical Consistency, and overall Usefulness/Effectiveness, Advanced Requirement One (Content-Related): Completeness, Thoroughness, Depth, Creativity, and Added Value, Advanced Requirement Two (Language-Related): Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**6 = From a human perspective, overall, the Response excellently addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Excellent Response.**
Because: It excels in all FOUR Specific Evaluation Criteria, and there seems to be no room for improvement.

**7 = From a human perspective, overall, the Response perfectly addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Perfect Response.** 
Because: It fully excels in all above FOUR Specific Evaluation Criteria, with NO room for improvement.



Note:
1) **Output format: Please return only a Python Dictionary, 100% STRICTLY following in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z}} where x,y,z are the placeholders that you should replace with the integer scores for each Response. NOTE: You are NOT allowed to modify the "key" of the Dictionary under any circumstances. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Do NOT allow the length of the responses to influence your evaluation. Carefully consider the content of the three Responses, and strictly adhere to the scoring guidelines to provide three precise scores.**


Now here are the Instruction, the Responses, and your judge result:

Instruction: {question}

Response One: {response1} 

Response Two: {response2} 

Response Three: {response3} 

Your Python dictionary containing the three scores:

"""

MULTI_5_INST_NEW2="""
You are an expert evaluator tasked with assessing the qualities of four Responses generated for an Instruction from the well-known instruction-following dataset AlpacaEval in NLP.
You will be provided with an Instruction and four Responses generated by different models.

Your task is to evaluate the overall qualities of four Responses by focusing on the following evaluation criteria:
Always keep in mind the "Core Evaluation Criteria"  Evaluate whether the Response effectively addresses the Instruction from a human perspective. Also, please focus on the following **FOUR Specific Evaluation Criteria**:
**Basic Requirement: Understanding the Question & Response Relevance**Does the Response understand and follow the Instruction without going off-topic or irrelevant? 
**Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness**: Does the Response correctly, reasonably, and logically answer the Instruction? Overall, does the Response meet the core requirements of the Instruction in terms of usefulness and effectiveness?
**Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value**: In cases where needed (especially for more open-ended Instructions), does the Response thoroughly cover all aspects of the Instruction's requirements, including all key points, relevant aspects, necessary information, steps for problem-solving needed to perfectly answer the Instruction? Does the Response go beyond surface-level answers and provide valuable, useful, creative, more in-depth information, offering added value and making the response more perfect?
**Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**: Does the Response use appropriate language that is clear, natural, coherent, fluent, concise, and easy to understand? Does the Response avoid vague, unnecessarily verbose, or repetitive statements? 


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5]. Please provide **four precise integer scores between [1, 2, 3, 4, 5]** by **strictly and meticulously adhering to the following scoring guidelines**:
**1 = From a human perspective, overall, the Response fails to address the Instructions needs, and it is a "Unrelevant, Unacceptable Response.**
Because: It fails to follow the above Basic Requirement: Understanding the Question & Response Relevance, let alone the more advanced requirements.  
**2 = From a human perspective, overall, the Response "partially addresses the Instructions needs, and it is a Relevant, Useful Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has several obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
**3 = From a human perspective, overall, the Response sufficiently addresses the Instructions needs, and it is a Relevant, Useful, Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  and it  **has minor, subtle shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
**4 = From a human perspective, overall, the Response excellently addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Excellent Response.**
Because: It meets the Basic Requirement: Understanding the Question & Response Relevance, and **there may be minor room for improvement in the following criteria: Core Requirement: Correctness, Reasonableness, Logical Consistency, and overall Usefulness/Effectiveness, Advanced Requirement One (Content-Related): Completeness, Thoroughness, Depth, Creativity, and Added Value, Advanced Requirement Two (Language-Related): Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
**5 = From a human perspective, overall, the Response perfectly addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Perfect Response.** 
Because: It fully excels in all above FOUR Specific Evaluation Criteria, with NO room for improvement.

 

Note:
1) **Output format: Please return only a Python Dictionary, 100% STRICTLY following in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z, "Score for the Response Three": w}} where x,y,z,w are the placeholders that you should replace with the integer scores for each Response. NOTE: You are NOT allowed to modify the "key" of the Dictionary under any circumstances. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Do NOT allow the length of the responses to influence your evaluation. Carefully consider the content of the four Responses, and strictly adhere to the scoring guidelines to provide four precise scores.**



Now here are the Instruction, the Responses, and your judge result:

Instruction: {question}

Response One: {response1} 

Response Two: {response2} 

Response Three: {response3} 

Response Four: {response4} 

Your Python Dictionary containing the four scores:

"""

MULTI_10_INST_NEW2="""
You are an expert evaluator tasked with assessing the qualities of four Responses generated for an Instruction from the well-known instruction-following dataset AlpacaEval in NLP.
You will be provided with an Instruction and four Responses generated by different models.

Your task is to evaluate the overall qualities of four Responses by focusing on the following evaluation criteria:
Always keep in mind the "Core Evaluation Criteria"  Evaluate whether the Response effectively addresses the Instruction from a human perspective. Also, please focus on the following **FOUR Specific Evaluation Criteria**:
**Basic Requirement: Understanding the Question & Response Relevance**Does the Response understand and follow the Instruction without going off-topic or irrelevant? 
**Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness**: Does the Response correctly, reasonably, and logically answer the Instruction? Overall, does the Response meet the core requirements of the Instruction in terms of usefulness and effectiveness?
**Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value**: In cases where needed (especially for more open-ended Instructions), does the Response thoroughly cover all aspects of the Instruction's requirements, including all key points, relevant aspects, necessary information, steps for problem-solving needed to perfectly answer the Instruction? Does the Response go beyond surface-level answers and provide valuable, useful, creative, more in-depth information, offering added value and making the response more perfect?
**Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**: Does the Response use appropriate language that is clear, natural, coherent, fluent, concise, and easy to understand? Does the Response avoid vague, unnecessarily verbose, or repetitive statements? 


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]. Please provide **four precise integer scores between [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]** by **strictly and meticulously adhering to the following scoring guidelines**:
**1 = From a human perspective, overall, the Response fails to address the Instructions needs, and it is a "Unrelevant, Unacceptable Response.**
Because: It fails to meet the above Basic Requirement: Understanding the Question & Response Relevance, let alone the more advanced requirements.  

**2 = From a human perspective, overall, the Response "partially addresses the Instructions needs to a small extent, and it is a Relevant, Low-Utility Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has too many serious and obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**3 = From a human perspective, overall, the Response "partially addresses the Instructions needs to a moderate extent, and it is a Relevant, Moderately Useful Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has several serious and obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**4 = From a human perspective, overall, the Response "partially addresses the Instructions needs to a large extent, and it is a Relevant, Useful Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has several obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**5 = From a human perspective, overall, the Response almost addresses the Instructions needs, and it is a Relevant, Useful, Minimally Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has noticeable shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**6 = From a human perspective, overall, the Response sufficiently addresses the Instructions needs, and it is a Relevant, Useful, Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  and it  **has minor, subtle shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**7 = From a human perspective, overall, the Response effectively addresses the Instructions needs, and it is a Relevant, Useful, Acceptable, Good Response.**
Because: It meets the Basic Requirement: Understanding the Question & Response Relevance, and **there may be minor room for improvement in the following criteria: Core Requirement: Correctness, Reasonableness, Logical Consistency, and overall Usefulness/Effectiveness, Advanced Requirement One (Content-Related): Completeness, Thoroughness, Depth, Creativity, and Added Value, Advanced Requirement Two (Language-Related): Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**8 = From a human perspective, overall, the Response excellently addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Excellent Response.**
Because: It excels in all FOUR Specific Evaluation Criteria, and there seems to be no room for improvement.

**9 = From a human perspective, overall, the Response perfectly addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Perfect Response.** 
Because: It fully excels in all above FOUR Specific Evaluation Criteria, with NO room for improvement.

**10 = From a human perspective, overall, the Response exceeds expectations and very perfectly addresses the Instructions needs, and it is a Relevant, Useful, Very Strong Acceptable, Very Perfect Response.**
Because: It fully excels in all above FOUR Specific Evaluation Criteria, with NO room for improvement.

 

Note:
1) **Output format: Please return only a Python Dictionary, 100% STRICTLY following in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z, "Score for the Response Three": w}} where x,y,z,w are the placeholders that you should replace with the integer scores for each Response. NOTE: You are NOT allowed to modify the "key" of the Dictionary under any circumstances. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Do NOT allow the length of the responses to influence your evaluation. Carefully consider the content of the four Responses, and strictly adhere to the scoring guidelines to provide four precise scores.**



Now here are the Instruction, the Responses, and your judge result:

Instruction: {question}

Response One: {response1} 

Response Two: {response2} 

Response Three: {response3} 

Response Four: {response4} 

Your Python Dictionary containing the four scores:

"""

MULTI_3_INST_NEW2="""
You are an expert evaluator tasked with assessing the qualities of four Responses generated for an Instruction from the well-known instruction-following dataset AlpacaEval in NLP.
You will be provided with an Instruction and four Responses generated by different models.

Your task is to evaluate the overall qualities of four Responses by focusing on the following evaluation criteria:
Always keep in mind the "Core Evaluation Criteria"  Evaluate whether the Response effectively addresses the Instruction from a human perspective. Also, please focus on the following **FOUR Specific Evaluation Criteria**:
**Basic Requirement: Understanding the Question & Response Relevance**Does the Response understand and follow the Instruction without going off-topic or irrelevant? 
**Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness**: Does the Response correctly, reasonably, and logically answer the Instruction? Overall, does the Response meet the core requirements of the Instruction in terms of usefulness and effectiveness?
**Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value**: In cases where needed (especially for more open-ended Instructions), does the Response thoroughly cover all aspects of the Instruction's requirements, including all key points, relevant aspects, necessary information, steps for problem-solving needed to perfectly answer the Instruction? Does the Response go beyond surface-level answers and provide valuable, useful, creative, more in-depth information, offering added value and making the response more perfect?
**Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**: Does the Response use appropriate language that is clear, natural, coherent, fluent, concise, and easy to understand? Does the Response avoid vague, unnecessarily verbose, or repetitive statements? 


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3]. Please provide **four precise integer scores between [1, 2, 3]** by **strictly and meticulously adhering to the following scoring guidelines**:
**1 = From a human perspective, overall, the Response fails to address Instructions needs or partially addresses the Instructions needs, and it is a Unacceptable Response.**
Because: It fails to meet the above Basic Requirement: Understanding the Question & Response Relevance, let alone the more advanced requirements; or, it meets the above Basic Requirement: Understanding the Question & Response Relevance,  but **has several obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**. 
**2 = From a human perspective, overall, the Response sufficiently addresses the Instructions needs, and it is a Relevant, Useful, Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  and it  **has minor, subtle shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.
**3 = From a human perspective, overall, the Response excellently or perfectly addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Excellent Response.**
Because: It meets the Basic Requirement: Understanding the Question & Response Relevance, and **there may be no room for improvement in the following criteria: Core Requirement: Correctness, Reasonableness, Logical Consistency, and overall Usefulness/Effectiveness, Advanced Requirement One (Content-Related): Completeness, Thoroughness, Depth, Creativity, and Added Value, Advanced Requirement Two (Language-Related): Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.



Note:
1) **Output format: Please return only a Python Dictionary, 100% STRICTLY following in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z, "Score for the Response Three": w}} where x,y,z,w are the placeholders that you should replace with the integer scores for each Response. NOTE: You are NOT allowed to modify the "key" of the Dictionary under any circumstances. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Do NOT allow the length of the responses to influence your evaluation. Carefully consider the content of the four Responses, and strictly adhere to the scoring guidelines to provide four precise scores.**



Now here are the Instruction, the Responses, and your judge result:

Instruction: {question}

Response One: {response1} 

Response Two: {response2} 

Response Three: {response3} 

Response Four: {response4} 

Your Python Dictionary containing the four scores:

"""

MULTI_7_INST_NEW2="""
You are an expert evaluator tasked with assessing the qualities of four Responses generated for an Instruction from the well-known instruction-following dataset AlpacaEval in NLP.
You will be provided with an Instruction and four Responses generated by different models.

Your task is to evaluate the overall qualities of four Responses by focusing on the following evaluation criteria:
Always keep in mind the "Core Evaluation Criteria"  Evaluate whether the Response effectively addresses the Instruction from a human perspective. Also, please focus on the following **FOUR Specific Evaluation Criteria**:
**Basic Requirement: Understanding the Question & Response Relevance**Does the Response understand and follow the Instruction without going off-topic or irrelevant? 
**Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness**: Does the Response correctly, reasonably, and logically answer the Instruction? Overall, does the Response meet the core requirements of the Instruction in terms of usefulness and effectiveness?
**Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value**: In cases where needed (especially for more open-ended Instructions), does the Response thoroughly cover all aspects of the Instruction's requirements, including all key points, relevant aspects, necessary information, steps for problem-solving needed to perfectly answer the Instruction? Does the Response go beyond surface-level answers and provide valuable, useful, creative, more in-depth information, offering added value and making the response more perfect?
**Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**: Does the Response use appropriate language that is clear, natural, coherent, fluent, concise, and easy to understand? Does the Response avoid vague, unnecessarily verbose, or repetitive statements? 


In line with the above evaluation criteria, here are the scoring guidelines between [1, 2, 3, 4, 5, 6, 7]. Please provide **four precise integer scores between [1, 2, 3, 4, 5, 6, 7]** by **strictly and meticulously adhering to the following scoring guidelines**:
**1 = From a human perspective, overall, the Response fails to address the Instructions needs, and it is a "Unrelevant, Unacceptable Response.**
Because: It fails to follow the above Basic Requirement: Understanding the Question & Response Relevance, let alone the more advanced requirements.  

**2 = From a human perspective, overall, the Response "partially addresses the Instructions needs, and it is a Relevant, Useful Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has several obvious shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**3 = From a human perspective, overall, the Response almost addresses the Instructions needs, and it is a Relevant, Useful, Minimally Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  but  **has noticeable shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**4 = From a human perspective, overall, the Response sufficiently addresses the Instructions needs, and it is a Relevant, Useful, Acceptable Response.**
Because: It meets the above Basic Requirement: Understanding the Question & Response Relevance,  and it  **has minor, subtle shortcomings in some of the the following aspects: Core Requirement: Correctness, Reasonableness, Logical Consistency, and Overall Usefulness/Effectiveness, Content-Related Advanced Requirement: Completeness, Thoroughness, Depth, Creativity, and Added Value, Language-Related Advanced Requirement: Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**5 = From a human perspective, overall, the Response effectively addresses the Instructions needs, and it is a Relevant, Useful, Acceptable, Good Response.**
Because: It meets the Basic Requirement: Understanding the Question & Response Relevance, and **there may be minor room for improvement in the following criteria: Core Requirement: Correctness, Reasonableness, Logical Consistency, and overall Usefulness/Effectiveness, Advanced Requirement One (Content-Related): Completeness, Thoroughness, Depth, Creativity, and Added Value, Advanced Requirement Two (Language-Related): Clarity, Naturalness, Coherence, Fluency, Conciseness, and Ease of Understanding**.

**6 = From a human perspective, overall, the Response excellently addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Excellent Response.**
Because: It excels in all FOUR Specific Evaluation Criteria, and there seems to be no room for improvement.

**7 = From a human perspective, overall, the Response perfectly addresses the Instructions needs, and it is a Relevant, Useful, Strongly Acceptable, Perfect Response.** 
Because: It fully excels in all above FOUR Specific Evaluation Criteria, with NO room for improvement.



Note:
1) **Output format: Please return only a Python Dictionary, 100% STRICTLY following in the format {{"Score for the Response One": x, "Score for the Response Two": y, "Score for the Response Three": z, "Score for the Response Three": w}} where x,y,z,w are the placeholders that you should replace with the integer scores for each Response. NOTE: You are NOT allowed to modify the "key" of the Dictionary under any circumstances. Do NOT include any additional opening, closing, explanation, or formatting.**
2) **Objectivity**:
- **Do not let the order of the Responses to introduce any bias in your scoring**: As an expert evaluator, you should strictly follow the scoring guidelines, ensuring that the order of the Responses does not influence your judgment in any way. You can reconsider and evaluate the Responses multiple times internally to absolutely ensure that "order" does not affect your final scores.
- **Please avoid any bias: Do NOT let your judgment be swayed by any conservatism or exaggeration. Do NOT allow the length of the responses to influence your evaluation. Carefully consider the content of the four Responses, and strictly adhere to the scoring guidelines to provide four precise scores.**



Now here are the Instruction, the Responses, and your judge result:

Instruction: {question}

Response One: {response1} 

Response Two: {response2} 

Response Three: {response3} 

Response Four: {response4} 

Your Python Dictionary containing the four scores:

"""


